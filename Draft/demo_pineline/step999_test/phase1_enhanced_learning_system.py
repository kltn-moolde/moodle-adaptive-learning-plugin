# -*- coding: utf-8 -*-
"""
PHASE 1: H·ªá th·ªëng AI G·ª£i √Ω H·ªçc t·∫≠p Th√¥ng minh - Phi√™n b·∫£n N√¢ng cao
================================================================

D·ª±a tr√™n ph√¢n t√≠ch d·ªØ li·ªáu th·ª±c t·∫ø t·ª´ Moodle v√† m√¥ h√¨nh Q-Learning hi·ªán c√≥,
thi·∫øt k·∫ø l·∫°i h·ªá th·ªëng v·ªõi state space chi ti·∫øt h∆°n v√† c√° nh√¢n h√≥a s√¢u h∆°n.

T√°c gi·∫£: AI Assistant
Ng√†y: 2024
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score, davies_bouldin_score
import json
import warnings
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from enum import Enum
import logging

warnings.filterwarnings('ignore')
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# =============================================================================
# 1. ƒê·ªäNH NGHƒ®A C√ÅC L·ªöP V√Ä ENUM
# =============================================================================

class LearningState(Enum):
    """C√°c tr·∫°ng th√°i h·ªçc t·∫≠p chi ti·∫øt d·ª±a tr√™n Moodle events"""
    # Tr·∫°ng th√°i c∆° b·∫£n
    VIEW_COURSE = "view_course"
    VIEW_MODULE = "view_module"
    VIEW_RESOURCE = "view_resource"
    
    # Tr·∫°ng th√°i Assignment
    VIEW_ASSIGNMENT = "view_assignment"
    START_ASSIGNMENT = "start_assignment"
    SUBMIT_ASSIGNMENT = "submit_assignment"
    VIEW_FEEDBACK = "view_feedback"
    
    # Tr·∫°ng th√°i Quiz
    VIEW_QUIZ = "view_quiz"
    START_QUIZ = "start_quiz"
    SUBMIT_QUIZ = "submit_quiz"
    REVIEW_QUIZ = "review_quiz"
    
    # Tr·∫°ng th√°i t∆∞∆°ng t√°c
    VIEW_GRADES = "view_grades"
    VIEW_PROGRESS = "view_progress"
    PARTICIPATE_DISCUSSION = "participate_discussion"
    DOWNLOAD_MATERIALS = "download_materials"
    
    # Tr·∫°ng th√°i ƒë·∫∑c bi·ªát
    SEEK_HELP = "seek_help"
    REVIEW_MISTAKES = "review_mistakes"
    PLAN_STUDY = "plan_study"

class LearningStyle(Enum):
    """Phong c√°ch h·ªçc t·∫≠p"""
    VISUAL = "visual"
    AUDITORY = "auditory"
    KINESTHETIC = "kinesthetic"
    READING_WRITING = "reading_writing"

class PerformanceLevel(Enum):
    """M·ª©c ƒë·ªô hi·ªáu su·∫•t"""
    EXCELLENT = "excellent"      # >= 0.8
    GOOD = "good"               # 0.6 - 0.8
    AVERAGE = "average"         # 0.4 - 0.6
    BELOW_AVERAGE = "below_avg" # 0.2 - 0.4
    POOR = "poor"               # < 0.2

@dataclass
class StudentProfile:
    """H·ªì s∆° c√° nh√¢n c·ªßa sinh vi√™n"""
    user_id: int
    cluster_id: int
    learning_style: LearningStyle
    performance_level: PerformanceLevel
    engagement_score: float
    completion_rate: float
    time_preference: str  # "morning", "afternoon", "evening"
    weak_areas: List[str]
    strong_areas: List[str]
    learning_goals: List[str]
    current_state: LearningState
    learning_history: List[LearningState]
    performance_trend: str  # "improving", "stable", "declining"

@dataclass
class LearningRecommendation:
    """G·ª£i √Ω h·ªçc t·∫≠p c√° nh√¢n"""
    student_id: int
    recommended_state: LearningState
    confidence_score: float
    reasoning: str
    expected_benefit: float
    time_estimate: int  # ph√∫t
    difficulty_level: str
    prerequisites: List[LearningState]

# =============================================================================
# 2. L·ªöP Q-LEARNING N√ÇNG CAO
# =============================================================================

class EnhancedQLearningAgent:
    """Q-Learning Agent n√¢ng cao v·ªõi kh·∫£ nƒÉng c√° nh√¢n h√≥a"""
    
    def __init__(self, n_states: int, n_actions: int, 
                 learning_rate: float = 0.1, 
                 discount: float = 0.95, 
                 epsilon: float = 0.1,
                 student_profile: Optional[StudentProfile] = None):
        self.n_states = n_states
        self.n_actions = n_actions
        self.lr = learning_rate
        self.gamma = discount
        self.epsilon = epsilon
        self.student_profile = student_profile
        
        # Q-table ch√≠nh
        self.q_table = np.zeros((n_states, n_actions))
        
        # Q-tables ph·ª• cho c√°c t√¨nh hu·ªëng ƒë·∫∑c bi·ªát
        self.help_q_table = np.zeros((n_states, n_actions))  # Khi c·∫ßn h·ªó tr·ª£
        self.excellent_q_table = np.zeros((n_states, n_actions))  # Khi h·ªçc t·ªët
        self.struggling_q_table = np.zeros((n_states, n_actions))  # Khi g·∫∑p kh√≥ khƒÉn
        
        # L·ªãch s·ª≠ h·ªçc t·∫≠p
        self.learning_history = []
        self.performance_history = []
        
    def choose_action(self, state: int, context: str = "normal") -> int:
        """Ch·ªçn action d·ª±a tr√™n context v√† profile c√° nh√¢n"""
        if context == "help_needed":
            q_table = self.help_q_table
        elif context == "excellent_performance":
            q_table = self.excellent_q_table
        elif context == "struggling":
            q_table = self.struggling_q_table
        else:
            q_table = self.q_table
            
        # Epsilon-greedy v·ªõi ƒëi·ªÅu ch·ªânh d·ª±a tr√™n profile
        if np.random.random() < self._get_adaptive_epsilon():
            return np.random.randint(self.n_actions)
        else:
            return np.argmax(q_table[state])
    
    def _get_adaptive_epsilon(self) -> float:
        """ƒêi·ªÅu ch·ªânh epsilon d·ª±a tr√™n profile sinh vi√™n"""
        base_epsilon = self.epsilon
        
        if self.student_profile:
            # Sinh vi√™n c√≥ performance cao -> √≠t exploration
            if self.student_profile.performance_level in [PerformanceLevel.EXCELLENT, PerformanceLevel.GOOD]:
                return base_epsilon * 0.5
            # Sinh vi√™n g·∫∑p kh√≥ khƒÉn -> nhi·ªÅu exploration
            elif self.student_profile.performance_level in [PerformanceLevel.POOR, PerformanceLevel.BELOW_AVERAGE]:
                return base_epsilon * 1.5
                
        return base_epsilon
    
    def learn(self, state: int, action: int, reward: float, 
              next_state: int, context: str = "normal"):
        """H·ªçc t·ª´ experience v·ªõi context awareness"""
        # C·∫≠p nh·∫≠t Q-table ch√≠nh
        current_q = self.q_table[state, action]
        max_next_q = np.max(self.q_table[next_state])
        new_q = current_q + self.lr * (reward + self.gamma * max_next_q - current_q)
        self.q_table[state, action] = new_q
        
        # C·∫≠p nh·∫≠t Q-table ph√π h·ª£p v·ªõi context
        if context == "help_needed":
            self._update_context_table(self.help_q_table, state, action, reward, next_state)
        elif context == "excellent_performance":
            self._update_context_table(self.excellent_q_table, state, action, reward, next_state)
        elif context == "struggling":
            self._update_context_table(self.struggling_q_table, state, action, reward, next_state)
        
        # L∆∞u l·ªãch s·ª≠
        self.learning_history.append({
            'state': state, 'action': action, 'reward': reward, 
            'next_state': next_state, 'context': context
        })
    
    def _update_context_table(self, q_table: np.ndarray, state: int, 
                            action: int, reward: float, next_state: int):
        """C·∫≠p nh·∫≠t Q-table cho context c·ª• th·ªÉ"""
        current_q = q_table[state, action]
        max_next_q = np.max(q_table[next_state])
        new_q = current_q + self.lr * (reward + self.gamma * max_next_q - current_q)
        q_table[state, action] = new_q
    
    def get_policy(self, context: str = "normal") -> np.ndarray:
        """L·∫•y policy t·ªëi ∆∞u cho context c·ª• th·ªÉ"""
        if context == "help_needed":
            return np.argmax(self.help_q_table, axis=1)
        elif context == "excellent_performance":
            return np.argmax(self.excellent_q_table, axis=1)
        elif context == "struggling":
            return np.argmax(self.struggling_q_table, axis=1)
        else:
            return np.argmax(self.q_table, axis=1)

# =============================================================================
# 3. H·ªÜ TH·ªêNG REWARD N√ÇNG CAO
# =============================================================================

class EnhancedRewardSystem:
    """H·ªá th·ªëng reward n√¢ng cao v·ªõi nhi·ªÅu y·∫øu t·ªë"""
    
    def __init__(self):
        # Base rewards cho t·ª´ng state
        self.base_rewards = {
            LearningState.VIEW_COURSE: 0.1,
            LearningState.VIEW_MODULE: 0.2,
            LearningState.VIEW_RESOURCE: 0.3,
            LearningState.VIEW_ASSIGNMENT: 0.4,
            LearningState.START_ASSIGNMENT: 0.6,
            LearningState.SUBMIT_ASSIGNMENT: 0.9,
            LearningState.VIEW_FEEDBACK: 0.5,
            LearningState.VIEW_QUIZ: 0.4,
            LearningState.START_QUIZ: 0.7,
            LearningState.SUBMIT_QUIZ: 1.0,
            LearningState.REVIEW_QUIZ: 0.6,
            LearningState.VIEW_GRADES: 0.3,
            LearningState.VIEW_PROGRESS: 0.4,
            LearningState.PARTICIPATE_DISCUSSION: 0.5,
            LearningState.DOWNLOAD_MATERIALS: 0.3,
            LearningState.SEEK_HELP: 0.8,
            LearningState.REVIEW_MISTAKES: 0.7,
            LearningState.PLAN_STUDY: 0.6
        }
        
        # Multipliers cho c√°c y·∫øu t·ªë kh√°c nhau
        self.performance_multipliers = {
            PerformanceLevel.EXCELLENT: 1.2,
            PerformanceLevel.GOOD: 1.1,
            PerformanceLevel.AVERAGE: 1.0,
            PerformanceLevel.BELOW_AVERAGE: 0.8,
            PerformanceLevel.POOR: 0.6
        }
        
        self.learning_style_multipliers = {
            LearningStyle.VISUAL: 1.1,
            LearningStyle.AUDITORY: 1.0,
            LearningStyle.KINESTHETIC: 1.05,
            LearningStyle.READING_WRITING: 1.08
        }
    
    def calculate_reward(self, current_state: LearningState, 
                        next_state: LearningState,
                        student_profile: StudentProfile,
                        context: str = "normal") -> float:
        """T√≠nh reward d·ª±a tr√™n nhi·ªÅu y·∫øu t·ªë"""
        
        # Base reward
        base_reward = self.base_rewards.get(next_state, 0.0)
        
        # Performance multiplier
        perf_multiplier = self.performance_multipliers.get(
            student_profile.performance_level, 1.0
        )
        
        # Learning style multiplier
        style_multiplier = self.learning_style_multipliers.get(
            student_profile.learning_style, 1.0
        )
        
        # Engagement bonus
        engagement_bonus = student_profile.engagement_score * 0.3
        
        # Completion rate bonus
        completion_bonus = student_profile.completion_rate * 0.2
        
        # Context-specific adjustments
        context_bonus = self._get_context_bonus(context, next_state)
        
        # Progress bonus (kh√¥ng l·∫∑p l·∫°i state)
        progress_bonus = 0.0
        if current_state != next_state:
            progress_bonus = 0.1
        
        # Difficulty penalty (n·∫øu chuy·ªÉn t·ª´ easy sang hard qu√° nhanh)
        difficulty_penalty = self._get_difficulty_penalty(current_state, next_state)
        
        # T√≠nh t·ªïng reward
        total_reward = (base_reward * perf_multiplier * style_multiplier + 
                       engagement_bonus + completion_bonus + 
                       context_bonus + progress_bonus - difficulty_penalty)
        
        return max(0.0, total_reward)  # ƒê·∫£m b·∫£o reward kh√¥ng √¢m
    
    def _get_context_bonus(self, context: str, state: LearningState) -> float:
        """Bonus d·ª±a tr√™n context"""
        if context == "help_needed" and state in [LearningState.SEEK_HELP, LearningState.REVIEW_MISTAKES]:
            return 0.3
        elif context == "excellent_performance" and state in [LearningState.SUBMIT_QUIZ, LearningState.SUBMIT_ASSIGNMENT]:
            return 0.2
        elif context == "struggling" and state in [LearningState.VIEW_RESOURCE, LearningState.VIEW_FEEDBACK]:
            return 0.4
        return 0.0
    
    def _get_difficulty_penalty(self, current_state: LearningState, 
                               next_state: LearningState) -> float:
        """Penalty n·∫øu chuy·ªÉn ƒë·ªïi kh√≥ khƒÉn qu√° nhanh"""
        # ƒê·ªãnh nghƒ©a ƒë·ªô kh√≥ c·ªßa c√°c states
        difficulty_levels = {
            LearningState.VIEW_COURSE: 1,
            LearningState.VIEW_MODULE: 2,
            LearningState.VIEW_RESOURCE: 2,
            LearningState.VIEW_ASSIGNMENT: 3,
            LearningState.START_ASSIGNMENT: 4,
            LearningState.SUBMIT_ASSIGNMENT: 5,
            LearningState.VIEW_QUIZ: 3,
            LearningState.START_QUIZ: 4,
            LearningState.SUBMIT_QUIZ: 5,
            LearningState.REVIEW_QUIZ: 3,
            LearningState.SEEK_HELP: 2,
            LearningState.REVIEW_MISTAKES: 3,
            LearningState.PLAN_STUDY: 2
        }
        
        current_diff = difficulty_levels.get(current_state, 1)
        next_diff = difficulty_levels.get(next_state, 1)
        
        # Penalty n·∫øu nh·∫£y qu√° xa v·ªÅ ƒë·ªô kh√≥
        if next_diff - current_diff > 2:
            return 0.2
        
        return 0.0

# =============================================================================
# 4. H·ªÜ TH·ªêNG G·ª¢I √ù TH√îNG MINH
# =============================================================================

class IntelligentRecommendationSystem:
    """H·ªá th·ªëng g·ª£i √Ω th√¥ng minh v·ªõi kh·∫£ nƒÉng c√° nh√¢n h√≥a s√¢u"""
    
    def __init__(self, q_agents: Dict[int, EnhancedQLearningAgent],
                 reward_system: EnhancedRewardSystem):
        self.q_agents = q_agents
        self.reward_system = reward_system
        self.states = list(LearningState)
        self.state_to_idx = {state: idx for idx, state in enumerate(self.states)}
        
    def get_personalized_recommendation(self, student_profile: StudentProfile) -> LearningRecommendation:
        """T·∫°o g·ª£i √Ω c√° nh√¢n h√≥a cho sinh vi√™n"""
        
        # L·∫•y agent cho cluster c·ªßa sinh vi√™n
        agent = self.q_agents.get(student_profile.cluster_id)
        if not agent:
            raise ValueError(f"No agent found for cluster {student_profile.cluster_id}")
        
        # X√°c ƒë·ªãnh context d·ª±a tr√™n profile
        context = self._determine_context(student_profile)
        
        # L·∫•y policy t·ªëi ∆∞u cho context
        policy = agent.get_policy(context)
        
        # L·∫•y state hi·ªán t·∫°i
        current_state_idx = self.state_to_idx[student_profile.current_state]
        
        # L·∫•y action ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t
        recommended_action_idx = policy[current_state_idx]
        recommended_state = self.states[recommended_action_idx]
        
        # T√≠nh confidence score
        confidence_score = self._calculate_confidence_score(
            agent, current_state_idx, recommended_action_idx, context
        )
        
        # T·∫°o reasoning
        reasoning = self._generate_reasoning(student_profile, recommended_state, context)
        
        # ∆Ø·ªõc t√≠nh l·ª£i √≠ch
        expected_benefit = self._estimate_benefit(student_profile, recommended_state)
        
        # ∆Ø·ªõc t√≠nh th·ªùi gian
        time_estimate = self._estimate_time(recommended_state, student_profile)
        
        # X√°c ƒë·ªãnh ƒë·ªô kh√≥
        difficulty_level = self._get_difficulty_level(recommended_state)
        
        # X√°c ƒë·ªãnh prerequisites
        prerequisites = self._get_prerequisites(recommended_state)
        
        return LearningRecommendation(
            student_id=student_profile.user_id,
            recommended_state=recommended_state,
            confidence_score=confidence_score,
            reasoning=reasoning,
            expected_benefit=expected_benefit,
            time_estimate=time_estimate,
            difficulty_level=difficulty_level,
            prerequisites=prerequisites
        )
    
    def _determine_context(self, student_profile: StudentProfile) -> str:
        """X√°c ƒë·ªãnh context d·ª±a tr√™n profile sinh vi√™n"""
        if student_profile.performance_level in [PerformanceLevel.POOR, PerformanceLevel.BELOW_AVERAGE]:
            return "struggling"
        elif student_profile.performance_level in [PerformanceLevel.EXCELLENT, PerformanceLevel.GOOD]:
            return "excellent_performance"
        elif student_profile.engagement_score < 0.3:
            return "help_needed"
        else:
            return "normal"
    
    def _calculate_confidence_score(self, agent: EnhancedQLearningAgent, 
                                  current_state_idx: int, 
                                  recommended_action_idx: int,
                                  context: str) -> float:
        """T√≠nh confidence score cho recommendation"""
        if context == "help_needed":
            q_table = agent.help_q_table
        elif context == "excellent_performance":
            q_table = agent.excellent_q_table
        elif context == "struggling":
            q_table = agent.struggling_q_table
        else:
            q_table = agent.q_table
        
        # L·∫•y Q-value c·ªßa action ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t
        recommended_q = q_table[current_state_idx, recommended_action_idx]
        
        # L·∫•y Q-value cao nh·∫•t
        max_q = np.max(q_table[current_state_idx])
        
        # Confidence = t·ª∑ l·ªá Q-value c·ªßa action ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t so v·ªõi max
        confidence = recommended_q / max_q if max_q > 0 else 0.0
        
        return min(1.0, confidence)
    
    def _generate_reasoning(self, student_profile: StudentProfile, 
                          recommended_state: LearningState,
                          context: str) -> str:
        """T·∫°o l√Ω do cho recommendation"""
        reasoning_parts = []
        
        # D·ª±a tr√™n performance level
        if student_profile.performance_level == PerformanceLevel.POOR:
            reasoning_parts.append("D·ª±a tr√™n hi·ªáu su·∫•t hi·ªán t·∫°i, b·∫°n n√™n t·∫≠p trung v√†o c√°c ho·∫°t ƒë·ªông c∆° b·∫£n")
        elif student_profile.performance_level == PerformanceLevel.EXCELLENT:
            reasoning_parts.append("V·ªõi hi·ªáu su·∫•t xu·∫•t s·∫Øc, b·∫°n c√≥ th·ªÉ th·ª≠ th√°ch b·∫£n th√¢n v·ªõi c√°c ho·∫°t ƒë·ªông n√¢ng cao")
        
        # D·ª±a tr√™n learning style
        if student_profile.learning_style == LearningStyle.VISUAL:
            reasoning_parts.append("Phong c√°ch h·ªçc t·∫≠p tr·ª±c quan c·ªßa b·∫°n ph√π h·ª£p v·ªõi ho·∫°t ƒë·ªông n√†y")
        
        # D·ª±a tr√™n engagement
        if student_profile.engagement_score < 0.3:
            reasoning_parts.append("Ho·∫°t ƒë·ªông n√†y s·∫Ω gi√∫p tƒÉng c∆∞·ªùng s·ª± tham gia c·ªßa b·∫°n")
        
        # D·ª±a tr√™n context
        if context == "struggling":
            reasoning_parts.append("ƒê√¢y l√† b∆∞·ªõc ti·∫øp theo ph√π h·ª£p ƒë·ªÉ c·∫£i thi·ªán t√¨nh h√¨nh h·ªçc t·∫≠p")
        elif context == "excellent_performance":
            reasoning_parts.append("Ho·∫°t ƒë·ªông n√†y s·∫Ω gi√∫p b·∫°n duy tr√¨ v√† ph√°t tri·ªÉn th√™m k·ªπ nƒÉng")
        
        return ". ".join(reasoning_parts) + "."
    
    def _estimate_benefit(self, student_profile: StudentProfile, 
                         recommended_state: LearningState) -> float:
        """∆Ø·ªõc t√≠nh l·ª£i √≠ch c·ªßa recommendation"""
        # Base benefit t·ª´ reward system
        base_benefit = self.reward_system.base_rewards.get(recommended_state, 0.0)
        
        # ƒêi·ªÅu ch·ªânh d·ª±a tr√™n profile
        if recommended_state in student_profile.strong_areas:
            base_benefit *= 1.2
        elif recommended_state in student_profile.weak_areas:
            base_benefit *= 0.8
        
        return base_benefit
    
    def _estimate_time(self, recommended_state: LearningState, 
                      student_profile: StudentProfile) -> int:
        """∆Ø·ªõc t√≠nh th·ªùi gian c·∫ßn thi·∫øt (ph√∫t)"""
        time_estimates = {
            LearningState.VIEW_COURSE: 5,
            LearningState.VIEW_MODULE: 10,
            LearningState.VIEW_RESOURCE: 15,
            LearningState.VIEW_ASSIGNMENT: 10,
            LearningState.START_ASSIGNMENT: 30,
            LearningState.SUBMIT_ASSIGNMENT: 45,
            LearningState.VIEW_FEEDBACK: 10,
            LearningState.VIEW_QUIZ: 5,
            LearningState.START_QUIZ: 20,
            LearningState.SUBMIT_QUIZ: 30,
            LearningState.REVIEW_QUIZ: 15,
            LearningState.VIEW_GRADES: 5,
            LearningState.VIEW_PROGRESS: 10,
            LearningState.PARTICIPATE_DISCUSSION: 20,
            LearningState.DOWNLOAD_MATERIALS: 5,
            LearningState.SEEK_HELP: 15,
            LearningState.REVIEW_MISTAKES: 25,
            LearningState.PLAN_STUDY: 20
        }
        
        base_time = time_estimates.get(recommended_state, 15)
        
        # ƒêi·ªÅu ch·ªânh d·ª±a tr√™n performance level
        if student_profile.performance_level == PerformanceLevel.POOR:
            base_time *= 1.5  # C·∫ßn nhi·ªÅu th·ªùi gian h∆°n
        elif student_profile.performance_level == PerformanceLevel.EXCELLENT:
            base_time *= 0.8  # Ho√†n th√†nh nhanh h∆°n
        
        return int(base_time)
    
    def _get_difficulty_level(self, state: LearningState) -> str:
        """X√°c ƒë·ªãnh ƒë·ªô kh√≥ c·ªßa state"""
        difficulty_map = {
            LearningState.VIEW_COURSE: "D·ªÖ",
            LearningState.VIEW_MODULE: "D·ªÖ",
            LearningState.VIEW_RESOURCE: "D·ªÖ",
            LearningState.VIEW_ASSIGNMENT: "Trung b√¨nh",
            LearningState.START_ASSIGNMENT: "Kh√≥",
            LearningState.SUBMIT_ASSIGNMENT: "Kh√≥",
            LearningState.VIEW_FEEDBACK: "D·ªÖ",
            LearningState.VIEW_QUIZ: "Trung b√¨nh",
            LearningState.START_QUIZ: "Kh√≥",
            LearningState.SUBMIT_QUIZ: "Kh√≥",
            LearningState.REVIEW_QUIZ: "Trung b√¨nh",
            LearningState.VIEW_GRADES: "D·ªÖ",
            LearningState.VIEW_PROGRESS: "D·ªÖ",
            LearningState.PARTICIPATE_DISCUSSION: "Trung b√¨nh",
            LearningState.DOWNLOAD_MATERIALS: "D·ªÖ",
            LearningState.SEEK_HELP: "D·ªÖ",
            LearningState.REVIEW_MISTAKES: "Trung b√¨nh",
            LearningState.PLAN_STUDY: "Trung b√¨nh"
        }
        
        return difficulty_map.get(state, "Trung b√¨nh")
    
    def _get_prerequisites(self, state: LearningState) -> List[LearningState]:
        """X√°c ƒë·ªãnh prerequisites cho state"""
        prerequisites_map = {
            LearningState.VIEW_ASSIGNMENT: [LearningState.VIEW_COURSE, LearningState.VIEW_MODULE],
            LearningState.START_ASSIGNMENT: [LearningState.VIEW_ASSIGNMENT],
            LearningState.SUBMIT_ASSIGNMENT: [LearningState.START_ASSIGNMENT],
            LearningState.VIEW_QUIZ: [LearningState.VIEW_COURSE, LearningState.VIEW_MODULE],
            LearningState.START_QUIZ: [LearningState.VIEW_QUIZ],
            LearningState.SUBMIT_QUIZ: [LearningState.START_QUIZ],
            LearningState.REVIEW_QUIZ: [LearningState.SUBMIT_QUIZ],
            LearningState.VIEW_FEEDBACK: [LearningState.SUBMIT_ASSIGNMENT],
            LearningState.REVIEW_MISTAKES: [LearningState.VIEW_FEEDBACK, LearningState.REVIEW_QUIZ],
            LearningState.SEEK_HELP: [LearningState.VIEW_COURSE]
        }
        
        return prerequisites_map.get(state, [])

# =============================================================================
# 5. H·ªÜ TH·ªêNG PH√ÇN T√çCH V√Ä X·ª¨ L√ù D·ªÆ LI·ªÜU
# =============================================================================

class DataProcessor:
    """X·ª≠ l√Ω v√† ph√¢n t√≠ch d·ªØ li·ªáu h·ªçc t·∫≠p"""
    
    def __init__(self, data_path: str):
        self.data_path = data_path
        self.df = None
        self.feature_columns = []
        self.load_data()
    
    def load_data(self):
        """T·∫£i d·ªØ li·ªáu t·ª´ file JSON"""
        with open(self.data_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        self.df = pd.DataFrame(data)
        logger.info(f"Loaded {len(self.df)} students with {len(self.df.columns)} features")
    
    def create_enhanced_features(self):
        """T·∫°o c√°c features n√¢ng cao t·ª´ d·ªØ li·ªáu g·ªëc"""
        # Features c∆° b·∫£n
        self.df['engagement_score'] = (
            self.df['viewed'] + self.df['submitted'] + self.df['created']
        ) / 3
        
        self.df['assignment_completion'] = self.df['\\mod_assign\\event\\assessable_submitted']
        self.df['quiz_participation'] = (
            self.df['\\mod_quiz\\event\\attempt_started'] + 
            self.df['\\mod_quiz\\event\\attempt_submitted']
        ) / 2
        
        # Features n√¢ng cao
        self.df['resource_utilization'] = (
            self.df['\\mod_resource\\event\\course_module_viewed'] +
            self.df['\\mod_folder\\event\\course_module_viewed'] +
            self.df['\\mod_page\\event\\course_module_viewed']
        ) / 3
        
        self.df['feedback_engagement'] = (
            self.df['\\mod_assign\\event\\feedback_viewed'] +
            self.df['\\mod_quiz\\event\\attempt_reviewed']
        ) / 2
        
        self.df['progress_tracking'] = (
            self.df['\\gradereport_user\\event\\grade_report_viewed'] +
            self.df['\\core\\event\\course_module_completion_updated']
        ) / 2
        
        self.df['interaction_level'] = (
            self.df['\\mod_forum\\event\\course_module_viewed'] +
            self.df['\\assignsubmission_comments\\event\\comment_created']
        ) / 2
        
        # X√°c ƒë·ªãnh learning style d·ª±a tr√™n h√†nh vi
        self.df['learning_style'] = self._infer_learning_style()
        
        # X√°c ƒë·ªãnh performance level
        self.df['performance_level'] = self._infer_performance_level()
        
        # X√°c ƒë·ªãnh weak v√† strong areas
        self.df['weak_areas'] = self._identify_weak_areas()
        self.df['strong_areas'] = self._identify_strong_areas()
        
        logger.info("Enhanced features created successfully")
    
    def _infer_learning_style(self) -> pd.Series:
        """Suy lu·∫≠n learning style t·ª´ h√†nh vi"""
        styles = []
        
        for _, row in self.df.iterrows():
            # Visual: xem nhi·ªÅu resource, √≠t t∆∞∆°ng t√°c
            visual_score = row['resource_utilization'] - row['interaction_level']
            
            # Auditory: tham gia discussion, xem feedback
            auditory_score = row['interaction_level'] + row['feedback_engagement']
            
            # Kinesthetic: l√†m assignment, quiz nhi·ªÅu
            kinesthetic_score = row['assignment_completion'] + row['quiz_participation']
            
            # Reading/Writing: xem t√†i li·ªáu, t·∫°o content
            rw_score = row['viewed'] + row['created']
            
            scores = {
                'visual': visual_score,
                'auditory': auditory_score,
                'kinesthetic': kinesthetic_score,
                'reading_writing': rw_score
            }
            
            styles.append(max(scores, key=scores.get))
        
        return pd.Series(styles)
    
    def _infer_performance_level(self) -> pd.Series:
        """Suy lu·∫≠n performance level t·ª´ ƒëi·ªÉm s·ªë"""
        levels = []
        
        for grade in self.df['mean_module_grade']:
            if grade >= 0.8:
                levels.append('excellent')
            elif grade >= 0.6:
                levels.append('good')
            elif grade >= 0.4:
                levels.append('average')
            elif grade >= 0.2:
                levels.append('below_avg')
            else:
                levels.append('poor')
        
        return pd.Series(levels)
    
    def _identify_weak_areas(self) -> pd.Series:
        """X√°c ƒë·ªãnh c√°c lƒ©nh v·ª±c y·∫øu"""
        weak_areas = []
        
        for _, row in self.df.iterrows():
            areas = []
            
            if row['assignment_completion'] < 0.3:
                areas.append('assignment')
            if row['quiz_participation'] < 0.3:
                areas.append('quiz')
            if row['resource_utilization'] < 0.3:
                areas.append('resource')
            if row['interaction_level'] < 0.3:
                areas.append('interaction')
            
            weak_areas.append(areas)
        
        return pd.Series(weak_areas)
    
    def _identify_strong_areas(self) -> pd.Series:
        """X√°c ƒë·ªãnh c√°c lƒ©nh v·ª±c m·∫°nh"""
        strong_areas = []
        
        for _, row in self.df.iterrows():
            areas = []
            
            if row['assignment_completion'] > 0.7:
                areas.append('assignment')
            if row['quiz_participation'] > 0.7:
                areas.append('quiz')
            if row['resource_utilization'] > 0.7:
                areas.append('resource')
            if row['interaction_level'] > 0.7:
                areas.append('interaction')
            
            strong_areas.append(areas)
        
        return pd.Series(strong_areas)
    
    def create_student_profiles(self) -> List[StudentProfile]:
        """T·∫°o student profiles t·ª´ d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω"""
        profiles = []
        
        for _, row in self.df.iterrows():
            profile = StudentProfile(
                user_id=row['userid'],
                cluster_id=row.get('cluster', 0),
                learning_style=LearningStyle(row['learning_style']),
                performance_level=PerformanceLevel(row['performance_level']),
                engagement_score=row['engagement_score'],
                completion_rate=row['assignment_completion'],
                time_preference="evening",  # M·∫∑c ƒë·ªãnh, c√≥ th·ªÉ c·∫£i thi·ªán
                weak_areas=row['weak_areas'],
                strong_areas=row['strong_areas'],
                learning_goals=["improve_performance"],  # M·∫∑c ƒë·ªãnh
                current_state=LearningState.VIEW_COURSE,  # M·∫∑c ƒë·ªãnh
                learning_history=[],
                performance_trend="stable"  # M·∫∑c ƒë·ªãnh
            )
            profiles.append(profile)
        
        return profiles

# =============================================================================
# 6. H√ÄM CH√çNH V√Ä DEMO
# =============================================================================

def main():
    """H√†m ch√≠nh ƒë·ªÉ demo h·ªá th·ªëng Phase 1"""
    logger.info("=== PHASE 1: H·ªÜ TH·ªêNG AI G·ª¢I √ù H·ªåC T·∫¨P TH√îNG MINH ===")
    
    # 1. X·ª≠ l√Ω d·ªØ li·ªáu
    logger.info("1. X·ª≠ l√Ω d·ªØ li·ªáu...")
    processor = DataProcessor("../data/features_scaled_report.json")
    processor.create_enhanced_features()
    
    # 2. T·∫°o student profiles
    logger.info("2. T·∫°o student profiles...")
    student_profiles = processor.create_student_profiles()
    
    # 3. Kh·ªüi t·∫°o h·ªá th·ªëng
    logger.info("3. Kh·ªüi t·∫°o h·ªá th·ªëng...")
    reward_system = EnhancedRewardSystem()
    
    # T·∫°o Q-agents cho c√°c clusters (gi·∫£ s·ª≠ c√≥ 3 clusters)
    q_agents = {}
    n_states = len(LearningState)
    n_actions = len(LearningState)
    
    for cluster_id in range(3):
        agent = EnhancedQLearningAgent(
            n_states=n_states,
            n_actions=n_actions,
            learning_rate=0.1,
            discount=0.95,
            epsilon=0.1
        )
        q_agents[cluster_id] = agent
    
    # 4. Kh·ªüi t·∫°o h·ªá th·ªëng g·ª£i √Ω
    recommendation_system = IntelligentRecommendationSystem(q_agents, reward_system)
    
    # 5. Demo g·ª£i √Ω cho m·ªôt s·ªë sinh vi√™n
    logger.info("4. Demo g·ª£i √Ω c√° nh√¢n h√≥a...")
    
    for i, profile in enumerate(student_profiles[:5]):  # Demo 5 sinh vi√™n ƒë·∫ßu
        logger.info(f"\n--- Sinh vi√™n {profile.user_id} ---")
        logger.info(f"Learning Style: {profile.learning_style.value}")
        logger.info(f"Performance Level: {profile.performance_level.value}")
        logger.info(f"Engagement Score: {profile.engagement_score:.3f}")
        logger.info(f"Weak Areas: {profile.weak_areas}")
        logger.info(f"Strong Areas: {profile.strong_areas}")
        
        # T·∫°o g·ª£i √Ω
        recommendation = recommendation_system.get_personalized_recommendation(profile)
        
        logger.info(f"\nüéØ G·ª¢I √ù:")
        logger.info(f"   Ho·∫°t ƒë·ªông: {recommendation.recommended_state.value}")
        logger.info(f"   ƒê·ªô tin c·∫≠y: {recommendation.confidence_score:.3f}")
        logger.info(f"   L√Ω do: {recommendation.reasoning}")
        logger.info(f"   L·ª£i √≠ch d·ª± ki·∫øn: {recommendation.expected_benefit:.3f}")
        logger.info(f"   Th·ªùi gian ∆∞·ªõc t√≠nh: {recommendation.time_estimate} ph√∫t")
        logger.info(f"   ƒê·ªô kh√≥: {recommendation.difficulty_level}")
        logger.info(f"   Prerequisites: {[s.value for s in recommendation.prerequisites]}")
    
    logger.info("\n=== PHASE 1 HO√ÄN TH√ÄNH ===")
    logger.info("H·ªá th·ªëng ƒë√£ s·∫µn s√†ng ƒë·ªÉ tri·ªÉn khai Phase 2!")

if __name__ == "__main__":
    main()
