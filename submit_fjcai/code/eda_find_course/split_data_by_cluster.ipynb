{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "484879be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DATA SPLITTER BY CLUSTER\n",
      "======================================================================\n",
      "‚úì Loaded 15 userids from 2 clusters\n",
      "  - cluster_0: 12 users\n",
      "  - cluster_1: 3 users\n",
      "\n",
      "üìä Processing grades file: ../data/udk_moodle_grades_course_670.filtered.csv\n",
      "   Total rows: 211\n",
      "   Filtered rows: 211 (100.0%)\n",
      "   ‚úì Saved grades_cluster_0.csv (183 rows)\n",
      "   ‚úì Saved grades_cluster_1.csv (28 rows)\n",
      "   ‚úì Saved individual user files to ../data/processed/split_by_cluster/by_user/grades/\n",
      "   ‚úì Saved summary to grades_summary.csv\n",
      "\n",
      "   Summary:\n",
      "           n_users  n_records\n",
      "cluster                      \n",
      "cluster_0       12        183\n",
      "cluster_1        3         28\n",
      "\n",
      "üìã Processing logs file: ../data/udk_moodle_log_course_670.filtered.csv\n",
      "   Total rows: 10833\n",
      "   Filtered rows: 10833 (100.0%)\n",
      "   ‚úì Saved logs_cluster_0.csv (10093 rows)\n",
      "   ‚úì Saved logs_cluster_1.csv (740 rows)\n",
      "   ‚úì Saved individual user files to ../data/processed/split_by_cluster/by_user/logs/\n",
      "\n",
      "   Top 5 events per cluster:\n",
      "cluster    eventname                                   \n",
      "cluster_0  \\core\\event\\course_viewed                       2862\n",
      "           \\mod_assign\\event\\course_module_viewed          2168\n",
      "           \\mod_assign\\event\\submission_status_viewed      1729\n",
      "           \\mod_resource\\event\\course_module_viewed         486\n",
      "           \\core\\event\\course_module_completion_updated     409\n",
      "cluster_1  \\mod_assign\\event\\course_module_viewed           197\n",
      "           \\core\\event\\course_viewed                        172\n",
      "           \\mod_assign\\event\\submission_status_viewed       171\n",
      "           \\mod_resource\\event\\course_module_viewed          28\n",
      "           \\mod_assign\\event\\feedback_viewed                 22\n",
      "\n",
      "   ‚úì Saved summary to logs_summary.csv\n",
      "\n",
      "   Summary:\n",
      "           n_users  n_events\n",
      "cluster                     \n",
      "cluster_0       12     10093\n",
      "cluster_1        2       740\n",
      "\n",
      "‚úì Saved split report to ../data/processed/split_by_cluster/split_report.json\n",
      "\n",
      "======================================================================\n",
      "‚úÖ SPLIT COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "Files created in: ../data/processed/split_by_cluster/\n",
      "\n",
      "Structure:\n",
      "  ‚îú‚îÄ‚îÄ grades_cluster_0.csv          # Grades for cluster 0\n",
      "  ‚îú‚îÄ‚îÄ grades_cluster_1.csv          # Grades for cluster 1\n",
      "  ‚îú‚îÄ‚îÄ logs_cluster_0.csv            # Logs for cluster 0\n",
      "  ‚îú‚îÄ‚îÄ logs_cluster_1.csv            # Logs for cluster 1\n",
      "  ‚îú‚îÄ‚îÄ grades_summary.csv            # Summary stats\n",
      "  ‚îú‚îÄ‚îÄ logs_summary.csv              # Summary stats\n",
      "  ‚îú‚îÄ‚îÄ split_report.json             # Complete report\n",
      "  ‚îî‚îÄ‚îÄ by_user/\n",
      "      ‚îú‚îÄ‚îÄ grades/\n",
      "      ‚îÇ   ‚îú‚îÄ‚îÄ grades_user_8609_cluster_0.csv\n",
      "      ‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
      "      ‚îî‚îÄ‚îÄ logs/\n",
      "          ‚îú‚îÄ‚îÄ logs_user_8609_cluster_0.csv\n",
      "          ‚îî‚îÄ‚îÄ ...\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Chia d·ªØ li·ªáu th√†nh c√°c file ri√™ng theo cluster v√† userid\n",
    "========================================================\n",
    "L·ªçc 2 file CSV (grades v√† logs) theo userid t·ª´ cluster_userids.json\n",
    "v√† xu·∫•t ra c√°c file ri√™ng cho m·ªói cluster v√† m·ªói user.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "class DataSplitter:\n",
    "    \"\"\"Class ƒë·ªÉ chia d·ªØ li·ªáu theo cluster\"\"\"\n",
    "    \n",
    "    def __init__(self, cluster_file: str, output_dir: str = None):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        cluster_file : str\n",
    "            ƒê∆∞·ªùng d·∫´n t·ªõi file cluster_userids.json\n",
    "        output_dir : str\n",
    "            Th∆∞ m·ª•c output (m·∫∑c ƒë·ªãnh: c√πng th∆∞ m·ª•c v·ªõi cluster_file)\n",
    "        \"\"\"\n",
    "        self.cluster_file = Path(cluster_file)\n",
    "        self.output_dir = Path(output_dir) if output_dir else self.cluster_file.parent / \"split_by_cluster\"\n",
    "        self.output_dir.mkdir(exist_ok=True, parents=True)\n",
    "        \n",
    "        # Load cluster userids\n",
    "        with open(self.cluster_file, 'r') as f:\n",
    "            self.cluster_data = json.load(f)\n",
    "        \n",
    "        # T·∫°o mapping ng∆∞·ª£c: userid -> cluster_id\n",
    "        self.userid_to_cluster = {}\n",
    "        for cluster_id, userids in self.cluster_data.items():\n",
    "            for uid in userids:\n",
    "                self.userid_to_cluster[uid] = cluster_id\n",
    "        \n",
    "        # All valid userids\n",
    "        self.valid_userids = list(self.userid_to_cluster.keys())\n",
    "        \n",
    "        print(f\"‚úì Loaded {len(self.valid_userids)} userids from {len(self.cluster_data)} clusters\")\n",
    "        for cluster_id, userids in self.cluster_data.items():\n",
    "            print(f\"  - {cluster_id}: {len(userids)} users\")\n",
    "    \n",
    "    def split_grades_file(self, grades_file: str):\n",
    "        \"\"\"\n",
    "        Chia file grades (c·∫•u tr√∫c: id, timemodified, userid, courseid, finalgrade, itemtype)\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        grades_file : str\n",
    "            ƒê∆∞·ªùng d·∫´n t·ªõi file CSV grades\n",
    "        \"\"\"\n",
    "        print(f\"\\nüìä Processing grades file: {grades_file}\")\n",
    "        \n",
    "        # Load grades\n",
    "        df = pd.read_csv(grades_file)\n",
    "        print(f\"   Total rows: {len(df)}\")\n",
    "        \n",
    "        # Ki·ªÉm tra c·ªôt\n",
    "        required_cols = ['userid']\n",
    "        if not all(col in df.columns for col in required_cols):\n",
    "            print(f\"   ‚ùå Missing required columns. Found: {df.columns.tolist()}\")\n",
    "            return\n",
    "        \n",
    "        # L·ªçc theo valid userids\n",
    "        df_filtered = df[df['userid'].isin(self.valid_userids)].copy()\n",
    "        print(f\"   Filtered rows: {len(df_filtered)} ({len(df_filtered)/len(df)*100:.1f}%)\")\n",
    "        \n",
    "        # Th√™m c·ªôt cluster\n",
    "        df_filtered['cluster'] = df_filtered['userid'].map(self.userid_to_cluster)\n",
    "        \n",
    "        # 1. Xu·∫•t file t·ªïng h·ª£p theo cluster\n",
    "        for cluster_id in self.cluster_data.keys():\n",
    "            cluster_df = df_filtered[df_filtered['cluster'] == cluster_id]\n",
    "            output_file = self.output_dir / f\"grades_{cluster_id}.csv\"\n",
    "            cluster_df.drop('cluster', axis=1).to_csv(output_file, index=False)\n",
    "            print(f\"   ‚úì Saved {output_file.name} ({len(cluster_df)} rows)\")\n",
    "        \n",
    "        # 2. Xu·∫•t file ri√™ng cho t·ª´ng user\n",
    "        user_dir = self.output_dir / \"by_user\" / \"grades\"\n",
    "        user_dir.mkdir(exist_ok=True, parents=True)\n",
    "        \n",
    "        for userid in self.valid_userids:\n",
    "            user_df = df_filtered[df_filtered['userid'] == userid]\n",
    "            if len(user_df) > 0:\n",
    "                cluster_id = self.userid_to_cluster[userid]\n",
    "                output_file = user_dir / f\"grades_user_{userid}_{cluster_id}.csv\"\n",
    "                user_df.drop('cluster', axis=1).to_csv(output_file, index=False)\n",
    "        \n",
    "        print(f\"   ‚úì Saved individual user files to {user_dir}/\")\n",
    "        \n",
    "        # 3. Summary stats\n",
    "        summary = df_filtered.groupby('cluster').agg({\n",
    "            'userid': 'nunique',\n",
    "            'id': 'count'\n",
    "        }).rename(columns={'userid': 'n_users', 'id': 'n_records'})\n",
    "        \n",
    "        summary_file = self.output_dir / \"grades_summary.csv\"\n",
    "        summary.to_csv(summary_file)\n",
    "        print(f\"   ‚úì Saved summary to {summary_file.name}\")\n",
    "        print(f\"\\n   Summary:\")\n",
    "        print(summary.to_string())\n",
    "        \n",
    "        return df_filtered\n",
    "    \n",
    "    def split_logs_file(self, logs_file: str):\n",
    "        \"\"\"\n",
    "        Chia file logs (c·∫•u tr√∫c: id, timecreated, eventname, action, target, userid, courseid, other)\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        logs_file : str\n",
    "            ƒê∆∞·ªùng d·∫´n t·ªõi file CSV logs\n",
    "        \"\"\"\n",
    "        print(f\"\\nüìã Processing logs file: {logs_file}\")\n",
    "        \n",
    "        # Load logs\n",
    "        df = pd.read_csv(logs_file)\n",
    "        print(f\"   Total rows: {len(df)}\")\n",
    "        \n",
    "        # Ki·ªÉm tra c·ªôt\n",
    "        required_cols = ['userid']\n",
    "        if not all(col in df.columns for col in required_cols):\n",
    "            print(f\"   ‚ùå Missing required columns. Found: {df.columns.tolist()}\")\n",
    "            return\n",
    "        \n",
    "        # L·ªçc theo valid userids\n",
    "        df_filtered = df[df['userid'].isin(self.valid_userids)].copy()\n",
    "        print(f\"   Filtered rows: {len(df_filtered)} ({len(df_filtered)/len(df)*100:.1f}%)\")\n",
    "        \n",
    "        # Th√™m c·ªôt cluster\n",
    "        df_filtered['cluster'] = df_filtered['userid'].map(self.userid_to_cluster)\n",
    "        \n",
    "        # S·∫Øp x·∫øp theo userid v√† timecreated\n",
    "        if 'timecreated' in df_filtered.columns:\n",
    "            df_filtered = df_filtered.sort_values(['userid', 'timecreated'])\n",
    "        \n",
    "        # 1. Xu·∫•t file t·ªïng h·ª£p theo cluster\n",
    "        for cluster_id in self.cluster_data.keys():\n",
    "            cluster_df = df_filtered[df_filtered['cluster'] == cluster_id]\n",
    "            output_file = self.output_dir / f\"logs_{cluster_id}.csv\"\n",
    "            cluster_df.drop('cluster', axis=1).to_csv(output_file, index=False)\n",
    "            print(f\"   ‚úì Saved {output_file.name} ({len(cluster_df)} rows)\")\n",
    "        \n",
    "        # 2. Xu·∫•t file ri√™ng cho t·ª´ng user\n",
    "        user_dir = self.output_dir / \"by_user\" / \"logs\"\n",
    "        user_dir.mkdir(exist_ok=True, parents=True)\n",
    "        \n",
    "        for userid in self.valid_userids:\n",
    "            user_df = df_filtered[df_filtered['userid'] == userid]\n",
    "            if len(user_df) > 0:\n",
    "                cluster_id = self.userid_to_cluster[userid]\n",
    "                output_file = user_dir / f\"logs_user_{userid}_{cluster_id}.csv\"\n",
    "                user_df.drop('cluster', axis=1).to_csv(output_file, index=False)\n",
    "        \n",
    "        print(f\"   ‚úì Saved individual user files to {user_dir}/\")\n",
    "        \n",
    "        # 3. Summary stats\n",
    "        summary = df_filtered.groupby('cluster').agg({\n",
    "            'userid': 'nunique',\n",
    "            'id': 'count'\n",
    "        }).rename(columns={'userid': 'n_users', 'id': 'n_events'})\n",
    "        \n",
    "        # Th√™m top events\n",
    "        if 'eventname' in df_filtered.columns:\n",
    "            top_events = df_filtered.groupby('cluster')['eventname'].value_counts().groupby(level=0).head(5)\n",
    "            print(f\"\\n   Top 5 events per cluster:\")\n",
    "            print(top_events.to_string())\n",
    "        \n",
    "        summary_file = self.output_dir / \"logs_summary.csv\"\n",
    "        summary.to_csv(summary_file)\n",
    "        print(f\"\\n   ‚úì Saved summary to {summary_file.name}\")\n",
    "        print(f\"\\n   Summary:\")\n",
    "        print(summary.to_string())\n",
    "        \n",
    "        return df_filtered\n",
    "    \n",
    "    def create_report(self, grades_df=None, logs_df=None):\n",
    "        \"\"\"\n",
    "        T·∫°o b√°o c√°o t·ªïng h·ª£p\n",
    "        \"\"\"\n",
    "        report = {\n",
    "            'total_users': len(self.valid_userids),\n",
    "            'clusters': {}\n",
    "        }\n",
    "        \n",
    "        for cluster_id, userids in self.cluster_data.items():\n",
    "            cluster_info = {\n",
    "                'n_users': len(userids),\n",
    "                'userids': userids\n",
    "            }\n",
    "            \n",
    "            if grades_df is not None:\n",
    "                cluster_grades = grades_df[grades_df['cluster'] == cluster_id]\n",
    "                cluster_info['grades_records'] = len(cluster_grades)\n",
    "            \n",
    "            if logs_df is not None:\n",
    "                cluster_logs = logs_df[logs_df['cluster'] == cluster_id]\n",
    "                cluster_info['log_events'] = len(cluster_logs)\n",
    "                \n",
    "                if 'eventname' in cluster_logs.columns:\n",
    "                    cluster_info['unique_event_types'] = cluster_logs['eventname'].nunique()\n",
    "            \n",
    "            report['clusters'][cluster_id] = cluster_info\n",
    "        \n",
    "        # Save report\n",
    "        report_file = self.output_dir / \"split_report.json\"\n",
    "        with open(report_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(report, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"\\n‚úì Saved split report to {report_file}\")\n",
    "        \n",
    "        return report\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function\"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"DATA SPLITTER BY CLUSTER\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Configuration\n",
    "    CLUSTER_FILE = \"../data/processed/cluster_userids.json\"\n",
    "    GRADES_FILE = \"../data/udk_moodle_grades_course_670.filtered.csv\"  # Thay ƒë·ªïi path n·∫øu c·∫ßn\n",
    "    LOGS_FILE = \"../data/udk_moodle_log_course_670.filtered.csv\"      # Thay ƒë·ªïi path n·∫øu c·∫ßn\n",
    "    OUTPUT_DIR = \"../data/processed/split_by_cluster\"\n",
    "    \n",
    "    # Initialize splitter\n",
    "    splitter = DataSplitter(CLUSTER_FILE, OUTPUT_DIR)\n",
    "    \n",
    "    # Split grades file\n",
    "    grades_df = None\n",
    "    if Path(GRADES_FILE).exists():\n",
    "        grades_df = splitter.split_grades_file(GRADES_FILE)\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  Grades file not found: {GRADES_FILE}\")\n",
    "    \n",
    "    # Split logs file\n",
    "    logs_df = None\n",
    "    if Path(LOGS_FILE).exists():\n",
    "        logs_df = splitter.split_logs_file(LOGS_FILE)\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  Logs file not found: {LOGS_FILE}\")\n",
    "    \n",
    "    # Create report\n",
    "    if grades_df is not None or logs_df is not None:\n",
    "        report = splitter.create_report(grades_df, logs_df)\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"‚úÖ SPLIT COMPLETE!\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"\\nFiles created in: {splitter.output_dir}/\")\n",
    "        print(f\"\\nStructure:\")\n",
    "        print(f\"  ‚îú‚îÄ‚îÄ grades_cluster_0.csv          # Grades for cluster 0\")\n",
    "        print(f\"  ‚îú‚îÄ‚îÄ grades_cluster_1.csv          # Grades for cluster 1\")\n",
    "        print(f\"  ‚îú‚îÄ‚îÄ logs_cluster_0.csv            # Logs for cluster 0\")\n",
    "        print(f\"  ‚îú‚îÄ‚îÄ logs_cluster_1.csv            # Logs for cluster 1\")\n",
    "        print(f\"  ‚îú‚îÄ‚îÄ grades_summary.csv            # Summary stats\")\n",
    "        print(f\"  ‚îú‚îÄ‚îÄ logs_summary.csv              # Summary stats\")\n",
    "        print(f\"  ‚îú‚îÄ‚îÄ split_report.json             # Complete report\")\n",
    "        print(f\"  ‚îî‚îÄ‚îÄ by_user/\")\n",
    "        print(f\"      ‚îú‚îÄ‚îÄ grades/\")\n",
    "        print(f\"      ‚îÇ   ‚îú‚îÄ‚îÄ grades_user_8609_cluster_0.csv\")\n",
    "        print(f\"      ‚îÇ   ‚îî‚îÄ‚îÄ ...\")\n",
    "        print(f\"      ‚îî‚îÄ‚îÄ logs/\")\n",
    "        print(f\"          ‚îú‚îÄ‚îÄ logs_user_8609_cluster_0.csv\")\n",
    "        print(f\"          ‚îî‚îÄ‚îÄ ...\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå No files processed!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
