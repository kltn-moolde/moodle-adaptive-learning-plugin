# Q-Learning for Moodle Adaptive Learning v2.0

Clean, modular implementation of Q-learning system for personalized learning recommendations.

## ğŸ“ Structure

```
step7_qlearning/
â”œâ”€â”€ core_v2/                    # Core modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ state_builder.py        # State representation (12 dims)
â”‚   â”œâ”€â”€ action_space.py         # Learning actions from course
â”‚   â”œâ”€â”€ reward_calculator.py    # Cluster-based rewards
â”‚   â”œâ”€â”€ qlearning_agent.py      # Tabular Q-learning
â”‚   â””â”€â”€ simulator.py            # Learning behavior simulator
â”‚
â”œâ”€â”€ data/                       # Data files
â”‚   â”œâ”€â”€ course_structure.json   # Moodle course structure
â”‚   â”œâ”€â”€ cluster_profiles.json   # Student cluster profiles
â”‚   â””â”€â”€ simulated/              # Simulated training data
â”‚
â”œâ”€â”€ models/                     # Trained models
â”‚   â””â”€â”€ qlearning_model.pkl     # Q-table + params
â”‚
â”œâ”€â”€ simulate_learning_data.py   # Generate simulated data
â”œâ”€â”€ train_qlearning_v2.py       # Train Q-learning model
â””â”€â”€ update_daily_qtable.py      # Daily update pipeline
```

## ğŸš€ Quick Start

### 1. Generate Simulated Data

```bash
python simulate_learning_data.py --n-students 100 --n-actions 30
```

**Output:** `data/simulated/latest_simulation.json`

### 2. Train Q-Learning Model

```bash
python train_qlearning_v2.py --data data/simulated/latest_simulation.json \
                              --output models/qlearning_model.pkl \
                              --epochs 10
```

**Output:** `models/qlearning_model.pkl`

### 3. Daily Update (Production)

```bash
# Run daily at 12AM
python update_daily_qtable.py --model models/qlearning_model.pkl
```

**Output:** 
- Updated Q-table
- Daily recommendations in `data/recommendations/`

## ğŸ”§ Core Components

### 1. State Builder (`state_builder.py`)

**12-dimensional state representation:**
- Performance (3): knowledge, engagement, struggle
- Activity patterns (5): submission, review, resources, assessment, collaboration
- Completion metrics (4): progress, completion rate, diversity, consistency

**Usage:**
```python
from core_v2 import MoodleStateBuilder

builder = MoodleStateBuilder()
state = builder.build_state(student_features)  # Returns np.array (12,)
```

### 2. Action Space (`action_space.py`)

**Extract learning actions from course:**
- Quiz, Assignment (assessment)
- Resource, Page, URL (content)
- Video, H5P (interactive)
- Forum (collaboration)

**Usage:**
```python
from core_v2 import ActionSpace

action_space = ActionSpace('data/course_structure.json')
actions = action_space.get_actions()  # List[LearningAction]
```

### 3. Reward Calculator (`reward_calculator.py`)

**Cluster-specific reward strategies:**
- **Weak (0-1):** High reward for completing assessments
- **Medium (2-3):** Balanced rewards
- **Strong (4-5):** Reward for speed and high scores

**Usage:**
```python
from core_v2 import RewardCalculator

calculator = RewardCalculator('data/cluster_profiles.json')
reward = calculator.calculate_reward(cluster_id, action, outcome, state)
```

### 4. Q-Learning Agent (`qlearning_agent.py`)

**Tabular Q-learning:**
- Îµ-greedy exploration
- Q-value updates: `Q(s,a) â† Q(s,a) + Î±[r + Î³ max Q(s',a') - Q(s,a)]`
- State hashing for continuous states

**Usage:**
```python
from core_v2 import QLearningAgent

agent = QLearningAgent(n_actions=50, learning_rate=0.1)
action = agent.select_action(state, available_actions)
agent.update(state, action, reward, next_state)
```

### 5. Simulator (`simulator.py`)

**Simulate learning behaviors:**
- Cluster-based behavior patterns
- Realistic outcomes (score, time, attempts)
- State transitions

**Usage:**
```python
from core_v2 import LearningSimulator

simulator = LearningSimulator(state_builder, action_space, reward_calc)
interactions = simulator.simulate_batch(n_students=100, n_actions_per_student=30)
```

## ğŸ“Š Data Flow

```
1. SIMULATION (offline)
   course_structure.json + cluster_profiles.json
   â†’ simulator.simulate_batch()
   â†’ simulated_data.json

2. TRAINING (offline)
   simulated_data.json
   â†’ agent.train_episode()
   â†’ qlearning_model.pkl

3. DAILY UPDATE (online)
   Moodle logs (12AM)
   â†’ extract_features()
   â†’ state_builder.build_state()
   â†’ agent.update()
   â†’ updated qlearning_model.pkl
   â†’ recommendations.json
```

## ğŸ”„ Daily Pipeline

**Automated workflow (runs at 12AM):**

1. **Fetch logs:** Get yesterday's Moodle logs
2. **Extract features:** Run feature extraction pipeline
3. **Build states:** Convert features â†’ state vectors
4. **Identify interactions:** Map logs â†’ (s, a, r, s')
5. **Update Q-table:** Apply Q-learning updates
6. **Save model:** Backup old + save new
7. **Generate recommendations:** Top-k actions per student

## ğŸ“ˆ Hyperparameters

| Parameter | Default | Description |
|-----------|---------|-------------|
| `learning_rate` (Î±) | 0.1 | Q-value update rate |
| `discount_factor` (Î³) | 0.95 | Future reward importance |
| `epsilon` (Îµ) | 0.1 | Exploration rate |
| `state_decimals` | 1 | State rounding (reduce sparsity) |

## ğŸ§ª Testing

```bash
# Test individual components
cd core_v2
python state_builder.py
python action_space.py
python reward_calculator.py
python qlearning_agent.py
python simulator.py
```

## ğŸ“¦ Dependencies

```
numpy
pickle (built-in)
json (built-in)
dataclasses (built-in)
```

## ğŸ¯ Extension Points

### Add new reward strategies:
Edit `reward_calculator.py` â†’ `_cluster_bonus()`

### Add new state features:
Edit `state_builder.py` â†’ `build_state()`

### Add new action types:
Edit `action_space.py` â†’ `MODULE_TYPE_MAPPING`

### Change exploration strategy:
Edit `qlearning_agent.py` â†’ `select_action()`

## ğŸ“ Notes

- **State hashing:** Rounds to 1 decimal to reduce Q-table sparsity
- **Cluster distribution:** Can customize in `simulator.simulate_batch()`
- **Action filtering:** Simulator filters by difficulty/purpose based on cluster
- **Reward clipping:** Rewards clipped to [-2, 5] range

## ğŸ› Troubleshooting

**Q-table too large?**
- Increase `state_decimals` in QLearningAgent
- Reduce state dimensions

**Low rewards?**
- Check reward calculation in `reward_calculator.py`
- Adjust cluster bonuses

**Poor recommendations?**
- Increase training data (more students/actions)
- Tune hyperparameters (Î±, Î³, Îµ)
- Check cluster assignment accuracy

## ğŸ“š References

- Q-Learning: Watkins & Dayan (1992)
- Moodle State Builder: Original implementation
- Cluster Profiles: From KMeans + GMM pipeline
