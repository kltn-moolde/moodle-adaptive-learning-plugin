# Q-Learning Training & Evaluation Pipeline

## ğŸ“‹ Tá»•ng quan

Pipeline hoÃ n chá»‰nh Ä‘á»ƒ:
1. **Simulate** dá»¯ liá»‡u há»c sinh dá»±a trÃªn cluster statistics
2. **Train** Q-Learning agent vá»›i dá»¯ liá»‡u simulated
3. **Evaluate** hiá»‡u suáº¥t vá»›i metrics chi tiáº¿t
4. **Visualize** káº¿t quáº£ vÃ  insights

## ğŸ”„ Quy trÃ¬nh

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    1. DATA SIMULATION                        â”‚
â”‚  Cluster Stats + Course Structure â†’ Student Profiles        â”‚
â”‚                    + Learning Trajectories                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    2. TRAIN/TEST SPLIT                       â”‚
â”‚         80% Train Set  |  20% Test Set                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    3. Q-LEARNING TRAINING                    â”‚
â”‚  Episodes â†’ Q-table Updates â†’ Policy Learning               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    4. EVALUATION                             â”‚
â”‚  Metrics + Visualizations + Report                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ File Structure

```
step7_qlearning/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ data_simulator.py          # Simulate student data
â”‚   â”œâ”€â”€ qlearning_agent_v2.py      # Q-Learning agent
â”‚   â””â”€â”€ ...
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ course_structure.json      # Course resources
â”‚   â”œâ”€â”€ features_scaled_report.json # Real student features
â”‚   â””â”€â”€ simulated/                 # Generated data
â”‚       â”œâ”€â”€ train_data.csv
â”‚       â”œâ”€â”€ test_data.csv
â”‚       â””â”€â”€ dataset_summary.json
â”œâ”€â”€ models/
â”‚   â””â”€â”€ qlearning_trained.pkl      # Trained model
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ training_history.json      # Training metrics
â”‚   â”œâ”€â”€ evaluation_metrics.json    # Test metrics
â”‚   â”œâ”€â”€ evaluation_report.txt      # Text report
â”‚   â””â”€â”€ visualizations/            # Plots
â”‚       â”œâ”€â”€ learning_curve.png
â”‚       â”œâ”€â”€ train_vs_test.png
â”‚       â””â”€â”€ metrics_heatmap.png
â”œâ”€â”€ train_qlearning.py             # Training script
â””â”€â”€ evaluate_qlearning.py          # Evaluation script
```

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install numpy pandas matplotlib seaborn tqdm scikit-learn
```

### 2. Run Complete Pipeline

```bash
cd demo_pineline/step7_qlearning

# Train (includes data simulation)
python train_qlearning.py

# Evaluate
python evaluate_qlearning.py
```

### 3. View Results

- **Metrics**: `results/evaluation_metrics.json`
- **Report**: `results/evaluation_report.txt`
- **Plots**: `results/visualizations/*.png`

## ğŸ“Š Metrics Explained

### Training Metrics

| Metric | Ã nghÄ©a | Range |
|--------|---------|-------|
| **Episode Reward** | Tá»•ng reward trong 1 episode (1 há»c sinh) | 0-10 |
| **Episode Length** | Sá»‘ bÆ°á»›c há»c (resources completed) | 1-15 |
| **Avg Q-value** | GiÃ¡ trá»‹ Q trung bÃ¬nh trong Q-table | -âˆ to +âˆ |

### Evaluation Metrics

| Metric | Ã nghÄ©a | CÃ´ng thá»©c | Good Value |
|--------|---------|-----------|------------|
| **Avg Reward** | Reward trung bÃ¬nh trÃªn táº­p test | Sum(rewards) / N | > 0.6 |
| **Avg Grade** | Äiá»ƒm trung bÃ¬nh Ä‘áº¡t Ä‘Æ°á»£c | Sum(grades) / N | > 0.7 |
| **Completion Rate** | Tá»· lá»‡ hoÃ n thÃ nh tÃ i nguyÃªn | Completed / Total | > 0.8 |
| **Recommendation Accuracy** | Top-K accuracy (khá»›p hÃ nh Ä‘á»™ng thá»±c táº¿) | Correct / Total | > 0.5 |
| **Avg Q-value** | GiÃ¡ trá»‹ Q trung bÃ¬nh (indicator of confidence) | Sum(Q) / N | > 0.3 |

### Reward Formula

```python
reward = 0.5 * grade + 0.2 * time_efficiency + 0.3 * completion
```

**Components:**
- `grade`: Äiá»ƒm Ä‘áº¡t Ä‘Æ°á»£c (0-1)
- `time_efficiency`: 1 - (time_spent / 60), shorter = better
- `completion`: 1.0 if completed, 0.0 otherwise

## ğŸ¯ Use Cases

### Use Case 1: Train tá»« Ä‘áº§u

```python
from core.data_simulator import StudentDataSimulator
from core.qlearning_agent_v2 import QLearningAgentV2
from train_qlearning import QLearningTrainer

# 1. Simulate data
simulator = StudentDataSimulator(...)
train_df, test_df = simulator.generate_dataset(n_students=100)

# 2. Train agent
agent = QLearningAgentV2.create_from_course(...)
trainer = QLearningTrainer(agent, train_df, test_df)
trainer.train(n_epochs=10)

# 3. Save
agent.save('models/my_model.pkl')
```

### Use Case 2: Load model vÃ  test

```python
from core.qlearning_agent_v2 import QLearningAgentV2

# Load trained model
agent = QLearningAgentV2.create_from_course(...)
agent.load('models/qlearning_trained.pkl')

# Get recommendation
state = [0.8, 0.7, ...]  # Student features
recommendations = agent.recommend(state, available_actions, top_k=5)
```

### Use Case 3: Thay Ä‘á»•i hyperparameters

```python
agent = QLearningAgentV2.create_from_course(
    course_json_path,
    n_bins=5,              # Sá»‘ bins (3, 5, 7)
    learning_rate=0.05,    # Learning rate (0.01-0.5)
    discount_factor=0.95,  # Gamma (0.8-0.99)
    epsilon=0.2            # Exploration rate (0.1-0.5)
)
```

## ğŸ“ˆ Interpreting Results

### Good Performance Indicators

âœ… **Learning Curve trending up**: Reward increases over epochs  
âœ… **Recommendation Accuracy > 50%**: Agent learns good policy  
âœ… **Small train-test gap**: Good generalization  
âœ… **Completion Rate > 80%**: Students complete resources  

### Warning Signs

âš ï¸ **Flat learning curve**: Hyperparameters cáº§n Ä‘iá»u chá»‰nh  
âš ï¸ **Low recommendation accuracy < 30%**: Q-table chÆ°a há»c tá»‘t  
âš ï¸ **Large train-test gap**: Overfitting  
âš ï¸ **Negative Q-values**: Reward function cáº§n review  

## ğŸ”§ Customization

### 1. Thay Ä‘á»•i reward function

Edit `train_qlearning.py`:

```python
def compute_reward(self, record: pd.Series) -> float:
    grade = record.get('grade', 0.0)
    time_spent = record.get('time_spent', 15)
    
    # Custom weights
    reward = (
        0.7 * grade +           # More weight on grade
        0.1 * time_reward +
        0.2 * completion_reward
    )
    return reward
```

### 2. ThÃªm cluster-aware training

```python
# In train_episode()
cluster_id = student_df.iloc[0]['cluster']

# Adjust learning rate by cluster
if cluster_id == 'cluster_1':  # Struggling students
    self.agent.alpha = 0.2  # Higher learning rate
else:
    self.agent.alpha = 0.1
```

### 3. Thay Ä‘á»•i sá»‘ lÆ°á»£ng students

```python
train_df, test_df = simulator.generate_dataset(
    n_students=500,           # More students
    train_ratio=0.7,          # 70-30 split
    n_steps_per_student=15    # More steps
)
```

## ğŸ› Troubleshooting

### Issue: "Q-table size is very small"

**Solution**: Increase n_bins or training epochs
```python
agent = QLearningAgentV2.create_from_course(..., n_bins=5)
trainer.train(n_epochs=20)
```

### Issue: "Recommendation accuracy is low"

**Solution**: 
1. Check reward function alignment
2. Increase training data
3. Reduce epsilon (less exploration)

### Issue: "Training is slow"

**Solution**:
1. Reduce n_students
2. Reduce n_steps_per_student
3. Use smaller n_bins

## ğŸ“š References

- Q-Learning: Watkins & Dayan (1992)
- State discretization: Sutton & Barto (2018)
- Adaptive learning: Khajah et al. (2016)

## ğŸ“ Notes

- **State space size**: n_bins^12 (e.g., 3^12 = 531,441 states)
- **Training time**: ~5-10 min for 100 students, 10 epochs
- **Memory**: Q-table size depends on visited states (typically < 10% of full space)

## âœ¨ Next Steps

1. **Add cluster-aware recommendations**: Adjust Q-values by cluster
2. **Implement Deep Q-Learning**: For larger state spaces
3. **Real-time learning**: Update Q-table from real student data
4. **Multi-objective optimization**: Balance multiple goals (grade, time, engagement)
