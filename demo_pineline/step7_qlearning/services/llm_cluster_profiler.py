#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LLM Cluster Profiler Service
=============================
Service Ä‘á»ƒ generate mÃ´ táº£ chi tiáº¿t vá» student clusters sá»­ dá»¥ng LLM
"""

import json
import logging
from pathlib import Path
from typing import Dict, List, Optional
import os

logger = logging.getLogger(__name__)


class LLMClusterProfiler:
    """
    Service sá»­ dá»¥ng LLM Ä‘á»ƒ phÃ¢n tÃ­ch vÃ  mÃ´ táº£ student clusters
    
    Features:
    - Generate natural language descriptions cho clusters
    - PhÃ¢n tÃ­ch strengths/weaknesses
    - ÄÆ°a ra recommendations cá»¥ thá»ƒ
    - Support Gemini vÃ  OpenAI
    """
    
    def __init__(self, 
                 cluster_profiles_path: str,
                 llm_provider: str = 'gemini',
                 api_key: Optional[str] = None):
        """
        Initialize LLM Cluster Profiler
        
        Args:
            cluster_profiles_path: Path to cluster_profiles.json
            llm_provider: 'gemini' or 'openai'
            api_key: API key (if None, read from env)
        """
        self.cluster_profiles_path = Path(cluster_profiles_path)
        self.llm_provider = llm_provider.lower()
        self.api_key = api_key
        self.llm_client = None
        self.cluster_profiles = None
        
        # Load cluster profiles
        self._load_cluster_profiles()
        
        # Initialize LLM
        self._initialize_llm()
    
    def _load_cluster_profiles(self):
        """Load cluster profiles from JSON"""
        if not self.cluster_profiles_path.exists():
            raise FileNotFoundError(f"Cluster profiles not found: {self.cluster_profiles_path}")
        
        with open(self.cluster_profiles_path, 'r', encoding='utf-8') as f:
            self.cluster_profiles = json.load(f)
        
        logger.info(f"âœ“ Loaded cluster profiles: {len(self.cluster_profiles.get('cluster_stats', {}))} clusters")
    
    def _initialize_llm(self):
        """Initialize LLM client"""
        try:
            if self.llm_provider == 'gemini':
                import google.generativeai as genai
                
                # Try: 1) provided api_key, 2) env vars, 3) config file
                api_key = self.api_key or os.getenv('GOOGLE_API_KEY') or os.getenv('GEMINI_API_KEY')
                
                # If still not found, try to load from config
                if not api_key:
                    try:
                        import sys
                        from pathlib import Path
                        config_path = Path(__file__).parent.parent / 'config.py'
                        if config_path.exists():
                            import importlib.util
                            spec = importlib.util.spec_from_file_location("config", config_path)
                            config = importlib.util.module_from_spec(spec)
                            spec.loader.exec_module(config)
                            api_key = getattr(config, 'GEMINI_API_KEY', '') or getattr(config, 'GOOGLE_API_KEY', '')
                    except Exception:
                        pass
                
                if not api_key:
                    raise ValueError("Gemini API key not found. Set GOOGLE_API_KEY/GEMINI_API_KEY env var or add to config.py")
                
                genai.configure(api_key=api_key)
                self.llm_client = genai.GenerativeModel('gemini-2.0-flash-exp')
                logger.info("âœ“ Initialized Gemini LLM")
                
            elif self.llm_provider == 'openai':
                from openai import OpenAI
                
                # Try: 1) provided api_key, 2) env var, 3) config file
                api_key = self.api_key or os.getenv('OPENAI_API_KEY')
                
                # If still not found, try to load from config
                if not api_key:
                    try:
                        import sys
                        from pathlib import Path
                        config_path = Path(__file__).parent.parent / 'config.py'
                        if config_path.exists():
                            import importlib.util
                            spec = importlib.util.spec_from_file_location("config", config_path)
                            config = importlib.util.module_from_spec(spec)
                            spec.loader.exec_module(config)
                            api_key = getattr(config, 'OPENAI_API_KEY', '')
                    except Exception:
                        pass
                
                if not api_key:
                    raise ValueError("OpenAI API key not found. Set OPENAI_API_KEY env var or add to config.py")
                
                self.llm_client = OpenAI(api_key=api_key)
                logger.info("âœ“ Initialized OpenAI LLM")
                
            else:
                raise ValueError(f"Unsupported LLM provider: {self.llm_provider}")
                
        except Exception as e:
            logger.error(f"Failed to initialize LLM: {e}")
            logger.warning("âš  LLM not available. Will use fallback descriptions.")
            self.llm_client = None
    
    def _format_top_features(self, cluster_data: Dict) -> str:
        """Format top distinguishing features cho prompt"""
        top_features = cluster_data.get('top_distinguishing_features', [])[:5]
        
        lines = []
        for feat_data in top_features:
            feat = feat_data.get('feature', 'unknown')
            interp = feat_data.get('interpretation', 'similar')
            z = feat_data.get('z_score', 0.0)
            lines.append(f"  - {feat}: {interp} (z-score: {z:.2f})")
        
        return '\n'.join(lines) if lines else "  - No distinguishing features"
    
    def generate_cluster_description(self, cluster_id: int) -> Dict:
        """
        Generate LLM description cho 1 cluster
        
        Args:
            cluster_id: Cluster ID
            
        Returns:
            Dict with name, description, strengths, weaknesses, recommendations
        """
        if not self.cluster_profiles:
            raise ValueError("Cluster profiles not loaded")
        
        cluster_stats = self.cluster_profiles.get('cluster_stats', {})
        cluster_key = str(cluster_id)
        
        if cluster_key not in cluster_stats:
            raise ValueError(f"Cluster {cluster_id} not found")
        
        cluster_data = cluster_stats[cluster_key]
        
        # If LLM not available, return fallback
        if not self.llm_client:
            return self._generate_fallback_description(cluster_data)
        
        # Prepare LLM prompt
        prompt = f"""
Báº¡n lÃ  má»™t chuyÃªn gia phÃ¢n tÃ­ch dá»¯ liá»‡u giÃ¡o dá»¥c trÃªn há»‡ thá»‘ng Moodle. HÃ£y phÃ¢n tÃ­ch vÃ  mÃ´ táº£ Ä‘áº·c Ä‘iá»ƒm cá»§a nhÃ³m há»c sinh sau:

**ThÃ´ng tin nhÃ³m:**
- Cluster ID: {cluster_id}
- Sá»‘ lÆ°á»£ng: {cluster_data.get('n_students', 0)} há»c sinh ({cluster_data.get('percentage', 0):.1f}% tá»•ng sá»‘)
- Top 5 Ä‘áº·c Ä‘iá»ƒm ná»•i báº­t so vá»›i overall:
{self._format_top_features(cluster_data)}

**YÃªu cáº§u:**
1. Äáº·t tÃªn ngáº¯n gá»n cho nhÃ³m nÃ y (tá»‘i Ä‘a 5 tá»«, vÃ­ dá»¥: "Há»c sinh Xuáº¥t sáº¯c ToÃ n diá»‡n", "Há»c sinh Cáº§n Há»— trá»£ CÆ¡ báº£n", v.v.)
2. MÃ´ táº£ Ä‘áº·c Ä‘iá»ƒm há»c táº­p cá»§a nhÃ³m (2-3 cÃ¢u, táº­p trung vÃ o hÃ nh vi há»c táº­p trÃªn Moodle)
3. PhÃ¢n tÃ­ch 2-3 Ä‘iá»ƒm máº¡nh chÃ­nh
4. PhÃ¢n tÃ­ch 2-3 Ä‘iá»ƒm yáº¿u/thÃ¡ch thá»©c chÃ­nh
5. Äá» xuáº¥t 3 hÃ nh Ä‘á»™ng cá»¥ thá»ƒ Ä‘á»ƒ há»— trá»£ hoáº·c phÃ¡t triá»ƒn nhÃ³m nÃ y

**LÆ°u Ã½:**
- PhÃ¢n tÃ­ch dá»±a trÃªn cÃ¡c features Moodle (course_viewed, submission, assessment, etc.)
- ÄÆ°a ra insights thá»±c táº¿, dá»… hiá»ƒu
- Recommendations pháº£i cá»¥ thá»ƒ, cÃ³ thá»ƒ thá»±c hiá»‡n Ä‘Æ°á»£c

**Äá»‹nh dáº¡ng tráº£ vá» (chá»‰ JSON, khÃ´ng cÃ³ markdown backticks):**
{{
    "profile_name": "TÃªn nhÃ³m ngáº¯n gá»n",
    "description": "MÃ´ táº£ ngáº¯n gá»n vá» Ä‘áº·c Ä‘iá»ƒm há»c táº­p",
    "strengths": ["Äiá»ƒm máº¡nh 1", "Äiá»ƒm máº¡nh 2", "Äiá»ƒm máº¡nh 3"],
    "weaknesses": ["Äiá»ƒm yáº¿u 1", "Äiá»ƒm yáº¿u 2"],
    "recommendations": ["HÃ nh Ä‘á»™ng 1", "HÃ nh Ä‘á»™ng 2", "HÃ nh Ä‘á»™ng 3"],
    "key_characteristics": ["Äáº·c Ä‘iá»ƒm 1", "Äáº·c Ä‘iá»ƒm 2"]
}}
"""
        
        try:
            # Call LLM
            if self.llm_provider == 'gemini':
                response = self.llm_client.generate_content(prompt)
                result_text = response.text
            else:  # openai
                response = self.llm_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {"role": "system", "content": "You are an educational data analyst. Always respond in Vietnamese and return valid JSON only."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.7
                )
                result_text = response.choices[0].message.content
            
            # Clean and parse JSON
            result_text = result_text.strip()
            
            # Remove markdown code blocks
            if result_text.startswith('```json'):
                result_text = result_text[7:]
            elif result_text.startswith('```'):
                result_text = result_text[3:]
            
            if result_text.endswith('```'):
                result_text = result_text[:-3]
            
            result_text = result_text.strip()
            
            # Parse JSON
            result = json.loads(result_text)
            
            # Validate required fields
            required_fields = ['profile_name', 'description', 'strengths', 'weaknesses', 'recommendations']
            for field in required_fields:
                if field not in result:
                    logger.warning(f"Missing field '{field}' in LLM response for cluster {cluster_id}")
                    result[field] = [] if field in ['strengths', 'weaknesses', 'recommendations'] else "N/A"
            
            logger.info(f"âœ“ Generated LLM description for Cluster {cluster_id}: {result.get('profile_name', 'N/A')}")
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse LLM JSON response for cluster {cluster_id}: {e}")
            logger.error(f"Response text: {result_text[:200]}...")
            return self._generate_fallback_description(cluster_data)
            
        except Exception as e:
            logger.error(f"LLM generation failed for cluster {cluster_id}: {e}")
            return self._generate_fallback_description(cluster_data)
    
    def _generate_fallback_description(self, cluster_data: Dict) -> Dict:
        """Generate basic description when LLM not available"""
        cluster_id = cluster_data.get('cluster_id', 0)
        n_students = cluster_data.get('n_students', 0)
        pct = cluster_data.get('percentage', 0)
        
        # Simple rule-based naming
        if pct > 40:
            name = f"NhÃ³m Äa sá»‘ ({pct:.0f}%)"
        elif pct < 10:
            name = f"NhÃ³m Thiá»ƒu sá»‘ ({pct:.0f}%)"
        else:
            name = f"NhÃ³m {cluster_id}"
        
        return {
            'profile_name': name,
            'description': f"NhÃ³m gá»“m {n_students} há»c sinh, chiáº¿m {pct:.1f}% tá»•ng sá»‘. Cáº§n phÃ¢n tÃ­ch chi tiáº¿t vá»›i LLM Ä‘á»ƒ cÃ³ insights Ä‘áº§y Ä‘á»§.",
            'strengths': ["Cáº§n phÃ¢n tÃ­ch vá»›i LLM Ä‘á»ƒ xÃ¡c Ä‘á»‹nh"],
            'weaknesses': ["Cáº§n phÃ¢n tÃ­ch vá»›i LLM Ä‘á»ƒ xÃ¡c Ä‘á»‹nh"],
            'recommendations': ["KÃ­ch hoáº¡t LLM (Gemini/OpenAI) Ä‘á»ƒ cÃ³ recommendations cá»¥ thá»ƒ"],
            'key_characteristics': ["Cáº§n LLM Ä‘á»ƒ phÃ¢n tÃ­ch"]
        }
    
    def generate_all_clusters(self) -> Dict:
        """
        Generate descriptions cho táº¥t cáº£ clusters
        
        Returns:
            Dict with all cluster profiles
        """
        if not self.cluster_profiles:
            raise ValueError("Cluster profiles not loaded")
        
        cluster_stats = self.cluster_profiles.get('cluster_stats', {})
        results = {}
        
        logger.info(f"Generating LLM descriptions for {len(cluster_stats)} clusters...")
        
        for cluster_key in sorted(cluster_stats.keys(), key=lambda x: int(x)):
            cluster_id = int(cluster_key)
            logger.info(f"\nğŸ“Š Analyzing Cluster {cluster_id}...")
            
            description = self.generate_cluster_description(cluster_id)
            
            # Add to results
            results[cluster_key] = {
                'cluster_id': cluster_id,
                'statistics': cluster_stats[cluster_key],
                'ai_profile': description
            }
        
        logger.info(f"\nâœ“ Generated descriptions for {len(results)} clusters")
        return results
    
    def save_profiles(self, output_path: str):
        """
        Save cluster profiles with LLM descriptions
        
        Args:
            output_path: Output file path (JSON)
        """
        profiles = self.generate_all_clusters()
        
        output = {
            'metadata': {
                'llm_provider': self.llm_provider,
                'n_clusters': len(profiles),
                'total_students': self.cluster_profiles.get('total_students', 0)
            },
            'clusters': profiles
        }
        
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output, f, indent=2, ensure_ascii=False)
        
        logger.info(f"âœ“ Saved LLM profiles to: {output_file}")
        
        # Also save human-readable report
        self._save_text_report(profiles, output_file.parent / 'cluster_profiles_llm_report.txt')
    
    def _save_text_report(self, profiles: Dict, output_path: Path):
        """Save human-readable text report"""
        lines = []
        lines.append("="*80)
        lines.append("CLUSTER PROFILING REPORT (LLM-POWERED)")
        lines.append("="*80)
        lines.append(f"\nLLM Provider: {self.llm_provider.upper()}")
        lines.append(f"Total Clusters: {len(profiles)}")
        lines.append(f"Total Students: {self.cluster_profiles.get('total_students', 0)}")
        
        for cluster_key in sorted(profiles.keys(), key=lambda x: int(x)):
            data = profiles[cluster_key]
            stats = data['statistics']
            ai = data['ai_profile']
            
            lines.append("\n" + "="*80)
            lines.append(f"CLUSTER {data['cluster_id']}: {ai.get('profile_name', 'N/A')}")
            lines.append("="*80)
            
            lines.append(f"\nğŸ“Š Thá»‘ng kÃª:")
            lines.append(f"  â€¢ Sá»‘ lÆ°á»£ng: {stats.get('n_students', 0)} há»c sinh ({stats.get('percentage', 0):.1f}%)")
            
            lines.append(f"\nğŸ“ MÃ´ táº£:")
            lines.append(f"  {ai.get('description', 'N/A')}")
            
            lines.append(f"\nğŸ¯ Äáº·c Ä‘iá»ƒm chÃ­nh:")
            for char in ai.get('key_characteristics', []):
                lines.append(f"  â€¢ {char}")
            
            lines.append(f"\nğŸ’ª Äiá»ƒm máº¡nh:")
            for strength in ai.get('strengths', []):
                lines.append(f"  â€¢ {strength}")
            
            lines.append(f"\nâš ï¸ Äiá»ƒm yáº¿u:")
            for weakness in ai.get('weaknesses', []):
                lines.append(f"  â€¢ {weakness}")
            
            lines.append(f"\nğŸ’¡ Äá» xuáº¥t hÃ nh Ä‘á»™ng:")
            for i, rec in enumerate(ai.get('recommendations', []), 1):
                lines.append(f"  {i}. {rec}")
        
        lines.append("\n" + "="*80)
        lines.append("END OF REPORT")
        lines.append("="*80)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))
        
        logger.info(f"âœ“ Saved text report to: {output_path}")
