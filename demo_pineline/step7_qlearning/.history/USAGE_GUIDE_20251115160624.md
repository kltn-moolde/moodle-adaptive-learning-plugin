# üìñ Usage Guide

## üìã M·ª•c l·ª•c

1. [API Usage](#api-usage)
2. [Training Guide](#training-guide)
3. [Simulation Guide](#simulation-guide)
4. [Examples](#examples)

---

## üì° API Usage

### Start Server

```bash
# Development
uvicorn api_service:app --reload --port 8080

# Production
uvicorn api_service:app --host 0.0.0.0 --port 8080 --workers 4
```

### Endpoints

#### 1. Health Check
```bash
curl http://localhost:8080/api/health
```

**Response:**
```json
{
  "status": "ok",
  "model_loaded": true,
  "n_actions": 15,
  "n_states_in_qtable": 7779
}
```

#### 2. Get Recommendations

**Request v·ªõi LO mastery (recommended)**:
```bash
curl -X POST http://localhost:8080/api/recommend \
  -H "Content-Type: application/json" \
  -d '{
    "student_id": 123,
    "features": {
      "cluster_id": 2,
      "current_module_id": 67,
      "module_progress": 0.75,
      "avg_score": 0.85,
      "recent_action_type": 1
    },
    "lo_mastery": {
      "LO1.1": 0.4,
      "LO1.2": 0.35,
      "LO2.2": 0.25,
      "LO2.4": 0.4
    },
    "top_k": 3
  }'
```

**Request kh√¥ng c√≥ LO mastery**:
```bash
curl -X POST http://localhost:8080/api/recommend \
  -H "Content-Type: application/json" \
  -d '{
    "student_id": 456,
    "features": {
      "cluster_id": 0,
      "current_module_id": 65,
      "module_progress": 0.5,
      "avg_score": 0.6,
      "recent_action_type": 0
    },
    "top_k": 5
  }'
```

**Input Validation**:
- **Required fields**: `current_module_id`, `module_progress`, `avg_score`
- **Optional fields**: `cluster_id` (0-4), `recent_action_type` (0-5)
- **Validation rules**:
  - `cluster_id`: int, range 0-4
  - `current_module_id`: int, ph·∫£i l√† module ID h·ª£p l·ªá
  - `module_progress`: float, range [0.0, 1.0]
  - `avg_score`: float, range [0.0, 1.0]
  - `recent_action_type`: int, range 0-5 (0=view_content, 1=submit_quiz, 2=post_forum, 3=review_quiz, 4=read_resource, 5=submit_assignment)
- **Invalid values**: API tr·∫£ v·ªÅ l·ªói 400 v·ªõi message r√µ r√†ng
- **Unused fields**: C·∫£nh b√°o v√† b·ªã b·ªè qua (nh∆∞ `is_stuck`, `quiz_attempts`, etc.)

**Response:**
```json
{
  "success": true,
  "student_id": 123,
  "cluster_id": 2,
  "cluster_name": "Medium",
  "state_vector": [2.0, 0.0, 0.75, 1.0, 1.0, 0.0],
  "state_description": {
    "cluster_id": 2,
    "cluster_name": "Medium",
    "module_index": 2,
    "progress_label": "75%",
    "score_label": "100%",
    "state_format": "6D"
  },
  "recommendations": [
    {
      "action_id": 2,
      "action_type": "attempt_quiz",
      "time_context": "past",
      "module_name": "attempt_quiz (past)",
      "q_value": 42.182,
      "activity_id": 63,
      "activity_name": "b√†i ki·ªÉm tra b√†i 2 - medium",
      "target_los": [["LO1.5", 0.4]],
      "explanation": "C·∫£i thi·ªán LO1.5 (hi·ªán t·∫°i 40.0%) ‚Üí d·ª± ki·∫øn tƒÉng 5.0% (l√™n 45.0%): ƒê√°nh gi√° ki·∫øn th·ª©c ·ª©ng d·ª•ng AI qua c√°c b√†i ki·ªÉm tra ·ªü c√°c m·ª©... | ƒê·ªô kh√≥: trung b√¨nh",
      "alternatives": []
    }
  ],
  "model_info": {
    "model_version": "V2",
    "n_states_in_qtable": 7779
  }
}
```

#### 3. Get Model Info
```bash
curl http://localhost:8080/api/model-info
```

#### 4. Get Top Positive States
```bash
curl "http://localhost:8080/api/qtable/states/positive?top_n=10"
```

### Python Client Example

```python
import requests

url = "http://localhost:8080/api/recommend"
payload = {
    "student_id": 123,
    "features": {
        "cluster_id": 2,
        "current_module_id": 67,
        "module_progress": 0.75,
        "avg_score": 0.85,
        "recent_action_type": 1
    },
    "lo_mastery": {
        "LO1.1": 0.4,
        "LO1.2": 0.35,
        "LO2.2": 0.25,
        "LO2.4": 0.4
    },
    "top_k": 5
}

response = requests.post(url, json=payload)
data = response.json()

print(f"Cluster: {data['cluster_name']} (ID: {data['cluster_id']})")
print(f"State: {data['state_vector']}")

for i, rec in enumerate(data["recommendations"], 1):
    print(f"\n{i}. {rec['module_name']} (Q={rec['q_value']:.3f})")
    print(f"   Activity: {rec.get('activity_name', 'N/A')} (ID: {rec.get('activity_id', 'N/A')})")
    print(f"   Explanation: {rec.get('explanation', 'N/A')}")
    if rec.get('target_los'):
        print(f"   Target LOs: {rec['target_los']}")
```

---

## üéì Training Guide

### Basic Training

```bash
# Training c∆° b·∫£n
python3 train_qlearning.py \
    --episodes 100 \
    --students 5 \
    --steps 30 \
    --output models/qtable.pkl
```

### Training v·ªõi Detailed Logging

```bash
# Enable detailed logging ƒë·ªÉ track state transitions
python3 train_qlearning.py \
    --episodes 100 \
    --students 5 \
    --steps 30 \
    --detailed-logging \
    --log-interval 10
```

**Output:**
- Q-table: `models/qtable.pkl`
- Training logs: `data/simulated/training_logs_episode_{N}.json`

### Parameters

| Parameter | Default | Description |
|-----------|---------|-------------|
| `--episodes` | 100 | Number of training episodes |
| `--students` | 5 | Students per cluster |
| `--steps` | 30 | Steps per episode |
| `--output` | `models/qtable.pkl` | Output Q-table path |
| `--detailed-logging` | False | Enable detailed state transition logging |
| `--log-interval` | 10 | Log every N episodes |
| `--log-output` | None | Custom log output path pattern |
| `--quiet` | False | Disable verbose output |

### Training Output

```
Episode 10/100
  Avg reward: 85.3
  Epsilon: 0.951
  Q-table states: 1,200
  Total updates: 4,500
  Avg LO mastery: 0.523
  ‚úì Detailed logs saved to data/simulated/training_logs_episode_10.json
```

### Training Log Format

M·ªói log file ch·ª©a:
- **Transitions**: Chi ti·∫øt t·ª´ng state transition
- **Statistics**: Exploration rate, reward stats, etc.

```json
{
  "transitions": [
    {
      "step": 1,
      "state": {...},
      "action": {...},
      "q_values": {...},
      "reward": {
        "total": 5.23,
        "breakdown": {
          "completion": 5.0,
          "score_improvement": 1.5,
          "lo_mastery_improvement": 0.23
        }
      },
      "lo_analysis": {...},
      "midterm_prediction": {...}
    }
  ],
  "statistics": {...}
}
```

---

## üé¨ Simulation Guide

### Basic Simulation

```bash
# Simulate v·ªõi trained model
python3 simulate_learning_path.py \
    --qtable models/qtable_best.pkl \
    --students 3 \
    --steps 30 \
    --output data/simulated/simulation.json
```

### Verbose Simulation

```bash
# Xem chi ti·∫øt t·ª´ng step
python3 simulate_learning_path.py \
    --qtable models/qtable_best.pkl \
    --students 1 \
    --steps 10 \
    --verbose
```

### Parameters

| Parameter | Default | Description |
|-----------|---------|-------------|
| `--qtable` | `models/qtable_best.pkl` | Path to trained Q-table |
| `--output` | `data/simulated/learning_path_simulation.json` | Output JSON path |
| `--students` | 3 | Number of students per cluster |
| `--steps` | 30 | Number of learning steps per student |
| `--clusters` | `weak medium strong` | Clusters to simulate |
| `--verbose` | False | Print detailed logs |
| `--no-save` | False | Do not save logs to JSON |

### Simulation Output

M·ªói simulation t·∫°o file JSON v·ªõi:
- **Simulation metadata**: Total students, avg reward, avg midterm
- **Per-student results**: 
  - State transitions chi ti·∫øt
  - LO summary v√† comparison
  - Midterm predictions
  - Statistics

### Example Output

```
Step 1 | Student 1000 (weak)
State: weak | Module module_0 | Progress 25% | Score 50%
       Phase: active | Engagement: medium

‚Üí Action Selected: submit_quiz
  Activity: Quiz tu·∫ßn 1 (ID: 67)
  Mode: ‚úÖ EXPLOITATION
  Q-value: 2.45

üìö Weak LOs Considered (3):
  - LO1.1: mastery=0.45, weight=0.10
  - LO1.2: mastery=0.50, weight=0.15

üìà LO Mastery Changes:
  - LO1.1: +0.05
  - LO1.2: +0.03

üí∞ Reward: 5.23
  Breakdown:
    - completion: 5.00
    - score_improvement: 1.50
    - lo_mastery_improvement: 0.23

üéØ Midterm Prediction: 12.5/20 (62.5%)
  Potential improvement: +3.2 points
```

---

## üí° Examples

### Example 1: Complete Training Workflow

```bash
# 1. Train model v·ªõi logging
python3 train_qlearning.py \
    --episodes 200 \
    --students 5 \
    --steps 30 \
    --detailed-logging \
    --log-interval 20 \
    --output models/qtable_new.pkl

# 2. Simulate ƒë·ªÉ ki·ªÉm tra
python3 simulate_learning_path.py \
    --qtable models/qtable_new.pkl \
    --students 3 \
    --steps 20 \
    --verbose

# 3. Start API server
uvicorn api_service:app --reload --port 8080
```

### Example 2: Python Integration

```python
from core.learning_path_simulator import LearningPathSimulator
from core.lo_mastery_tracker import LOMasteryTracker

# Initialize simulator
simulator = LearningPathSimulator(
    qtable_path='models/qtable_best.pkl',
    verbose=True
)

# Simulate single student
result = simulator.simulate_student(
    student_id=1001,
    cluster='weak',
    n_steps=30
)

# Get LO summary
lo_summary = result['lo_summary']
print(f"Predicted midterm: {lo_summary['midterm_prediction']['predicted_score']}/20")

# Get weak LOs
weak_los = lo_summary['weak_los']
for lo in weak_los:
    print(f"{lo['lo_id']}: mastery={lo['mastery']:.2f}, weight={lo['weight']:.2f}")
```

### Example 3: LO Mastery Tracking

```python
from core.lo_mastery_tracker import LOMasteryTracker

tracker = LOMasteryTracker()

# Initialize student
tracker.initialize_student(1001)

# Update mastery after activity
tracker.update_mastery(
    student_id=1001,
    lo_id='LO1.1',
    new_mastery=0.75,
    activity_id=54,
    timestamp=1
)

# Get weak LOs
weak_los = tracker.get_weak_los(1001, threshold=0.6)
print(f"Weak LOs: {len(weak_los)}")

# Predict midterm
prediction = tracker.predict_midterm_score(1001)
print(f"Predicted: {prediction['predicted_score']:.1f}/20")
print(f"Potential: {prediction['potential_score']:.1f}/20")

# Compare LOs
comparison = tracker.compare_los(1001)
print(f"Excellent: {comparison['statistics']['excellent_count']}")
print(f"Weak: {comparison['statistics']['weak_count']}")
```

### Example 4: API Integration v·ªõi Moodle

```python
import requests

def get_recommendations_for_student(student_data, lo_mastery=None):
    """Get recommendations from API v·ªõi activity details"""
    url = "http://localhost:8080/api/recommend"
    
    payload = {
        "student_id": student_data['id'],
        "features": {
            "cluster_id": student_data['cluster_id'],
            "current_module_id": student_data['current_module_id'],
            "module_progress": student_data['module_progress'],
            "avg_score": student_data['avg_score'],
            "recent_action_type": student_data['recent_action_type']
        },
        "top_k": 5
    }
    
    # Th√™m LO mastery n·∫øu c√≥
    if lo_mastery:
        payload['lo_mastery'] = lo_mastery
    
    response = requests.post(url, json=payload)
    return response.json()

# Usage
student = {
    'id': 123,
    'cluster_id': 2,
    'current_module_id': 67,
    'module_progress': 0.75,
    'avg_score': 0.85,
    'recent_action_type': 1
}

# LO mastery t·ª´ Moodle
lo_mastery = {
    'LO1.1': 0.4,
    'LO1.2': 0.35,
    'LO2.2': 0.25,
    'LO2.4': 0.4
}

result = get_recommendations_for_student(student, lo_mastery)
print(f"Cluster: {result['cluster_name']}")

for rec in result['recommendations']:
    print(f"\n‚Üí {rec['module_name']} (Q={rec['q_value']:.3f})")
    print(f"  üìö Activity: {rec.get('activity_name', 'N/A')}")
    print(f"  üí° {rec.get('explanation', 'N/A')}")
```

---

## üîç Debugging

### Check Q-table Coverage

```python
from services.model_loader import ModelLoader

loader = ModelLoader('models/qtable_best.pkl')
agent = loader.agent

stats = agent.get_statistics()
print(f"Q-table size: {stats['q_table_size']} states")
print(f"Total updates: {stats['total_updates']}")
```

### Analyze State Transitions

```python
import json

# Load training log
with open('data/simulated/training_logs_episode_10.json') as f:
    log = json.load(f)

# Analyze transitions
transitions = log['transitions']
print(f"Total transitions: {len(transitions)}")

# Count exploration vs exploitation
explore_count = sum(1 for t in transitions if t['action']['is_exploration'])
exploit_count = len(transitions) - explore_count
print(f"Exploration: {explore_count}, Exploitation: {exploit_count}")

# Average reward
avg_reward = sum(t['reward']['total'] for t in transitions) / len(transitions)
print(f"Average reward: {avg_reward:.2f}")
```

### Check LO Mastery Updates

```python
from core.lo_mastery_tracker import LOMasteryTracker

tracker = LOMasteryTracker()

# Get mastery history
history = tracker.get_mastery_history(1001)
for entry in history[-5:]:  # Last 5 updates
    print(f"{entry['lo_id']}: {entry['old_mastery']:.2f} ‚Üí {entry['new_mastery']:.2f} "
          f"(Œî={entry['delta']:+.3f})")
```

---

## üìä Performance Tips

### Training
- **Episodes**: 100-1000 t√πy v√†o ƒë·ªô ph·ª©c t·∫°p
- **Students**: 3-5 per cluster l√† ƒë·ªß
- **Steps**: 20-50 steps per episode
- **Logging**: Ch·ªâ enable khi c·∫ßn debug (overhead ~10-15%)

### Simulation
- **Students**: 1-3 ƒë·ªÉ test nhanh, 5-10 ƒë·ªÉ analysis
- **Steps**: 20-30 ƒë·ªÉ quick test, 50+ ƒë·ªÉ detailed analysis
- **Verbose**: Ch·ªâ b·∫≠t khi c·∫ßn xem chi ti·∫øt

### API
- **Response time**: < 50ms v·ªõi Q-table 7,779 states
- **Concurrent**: Supports multiple requests
- **Caching**: Model loader s·ª≠ d·ª•ng singleton pattern

---

## üêõ Troubleshooting

### Issue: Q-table not found
```bash
# Train model first
python3 train_qlearning.py --episodes 100
```

### Issue: Missing data files
```bash
# Check required files
ls data/course_structure.json
ls data/cluster_profiles.json
ls data/Po_Lo.json
ls data/midterm_lo_weights.json
```

### Issue: Low Q-values
```bash
# Retrain with more episodes
python3 train_qlearning.py --episodes 500
```

### Issue: Memory error during training
```bash
# Reduce students or steps
python3 train_qlearning.py --students 2 --steps 20
```

---

For architecture details, see **ARCHITECTURE.md**  
For quick start, see **README.md**

