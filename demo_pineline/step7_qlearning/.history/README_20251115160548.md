# ğŸ“ Adaptive Learning System - Q-Learning Recommendation Engine

**Version**: 2.0  
**Status**: âœ… Production Ready

## ğŸ“‹ Tá»•ng quan

Há»‡ thá»‘ng gá»£i Ã½ lá»™ trÃ¬nh há»c táº­p thÃ­ch á»©ng sá»­ dá»¥ng **Q-Learning**, Ä‘Æ°á»£c huáº¥n luyá»‡n tá»« dá»¯ liá»‡u mÃ´ phá»ng hÃ nh vi há»c sinh, phÃ¢n cá»¥m theo nÄƒng lá»±c há»c táº­p. Há»‡ thá»‘ng phÃ¢n tÃ­ch tráº¡ng thÃ¡i há»c táº­p hiá»‡n táº¡i cá»§a sinh viÃªn (cluster, module, tiáº¿n Ä‘á»™, Ä‘iá»ƒm sá»‘, hÃ nh Ä‘á»™ng gáº§n nháº¥t, tráº¡ng thÃ¡i stuck) Ä‘á»ƒ gá»£i Ã½ **top-K actions** tá»‘i Æ°u.

### âœ¨ TÃ­nh nÄƒng chÃ­nh

- **State 6D**: (cluster, module, progress, score, phase, engagement)
- **15 Actions**: Tá»« action space vá»›i time context (past/current/future)
- **37+ Learning Activities**: Tá»« course structure thá»±c táº¿
- **Cluster-Adaptive**: Chiáº¿n lÆ°á»£c reward khÃ¡c nhau cho tá»«ng cluster
- **LO Mastery Tracking**: Track vÃ  dá»± Ä‘oÃ¡n Ä‘iá»ƒm midterm dá»±a trÃªn Learning Outcomes
- **Intelligent Activity Selection**: Gá»£i Ã½ activity cá»¥ thá»ƒ dá»±a trÃªn LO yáº¿u vá»›i XAI explanations
- **LO Improvement Prediction**: Dá»± Ä‘oÃ¡n % cáº£i thiá»‡n LO sau khi hoÃ n thÃ nh activity
- **QTableAdapter**: Tá»± Ä‘á»™ng convert giá»¯a module IDs vÃ  action indices
- **REST API**: FastAPI vá»›i activity recommendations vÃ  explanations
- **Detailed Logging**: State transitions, reward breakdown, LO tracking

### ğŸ¯ Cáº£i tiáº¿n V2

| Metric | V1 | V2 | Cáº£i thiá»‡n |
|--------|----|----|-----------|
| **Q-table States** | 415 | 7,779+ | **18.7Ã—** â¬†ï¸ |
| **Coverage** | 1.2% | 18.2%+ | **15.2Ã—** â¬†ï¸ |
| **Training Episodes** | 500 | 1,000+ | **2Ã—** â¬†ï¸ |
| **State Dimensions** | ~10+ | 6 | ÄÆ¡n giáº£n hÆ¡n |
| **LO Integration** | âŒ | âœ… | Má»›i |

---

## ğŸš€ Quick Start

### 1. CÃ i Ä‘áº·t Dependencies

```bash
cd step7_qlearning
pip install -r requirements.txt
```

**Requirements:**
```
fastapi>=0.104.0
uvicorn>=0.24.0
numpy>=1.24.0
pandas>=2.0.0
scikit-learn>=1.3.0
matplotlib>=3.7.0
seaborn>=0.12.0
```

### 2. Training Model

```bash
# Training cÆ¡ báº£n
python3 train_qlearning.py --episodes 100 --students 5 --steps 30

# Training vá»›i detailed logging
python3 train_qlearning.py \
    --episodes 100 \
    --students 5 \
    --steps 30 \
    --detailed-logging \
    --log-interval 10
```

### 3. Khá»Ÿi Ä‘á»™ng API Server

```bash
# Development mode
uvicorn api_service:app --reload --port 8080

# Production mode
uvicorn api_service:app --host 0.0.0.0 --port 8080 --workers 4
```

### 4. Test API

```bash
# 1. Health check
curl http://localhost:8080/api/health

# 2. Get recommendations vá»›i LO mastery (recommended)
# Note: Chá»‰ cáº§n 5 trÆ°á»ng trong features Ä‘á»ƒ táº¡o 6D state:
#   - cluster_id, current_module_id, module_progress, avg_score, recent_action_type
#   - recent_action_type Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ tÃ­nh cáº£ learning_phase vÃ  engagement_level
# Validation: API sáº½ validate input vÃ  tráº£ vá» lá»—i náº¿u giÃ¡ trá»‹ khÃ´ng há»£p lá»‡
curl -X POST http://localhost:8080/api/recommend \
  -H "Content-Type: application/json" \
  -d '{
    "student_id": 123,
    "features": {
      "cluster_id": 2,
      "current_module_id": 67,
      "module_progress": 0.75,
      "avg_score": 0.85,
      "recent_action_type": 1
    },
    "lo_mastery": {
      "LO1.1": 0.4,
      "LO1.2": 0.35,
      "LO2.2": 0.25,
      "LO2.4": 0.4
    },
    "top_k": 3
  }'

# 3. Get recommendations khÃ´ng cÃ³ LO mastery (sáº½ dÃ¹ng default)
# Note: 5 trÆ°á»ng features â†’ 6D state (recent_action_type tÃ­nh 2 dimensions)
curl -X POST http://localhost:8080/api/recommend \
  -H "Content-Type: application/json" \
  -d '{
    "student_id": 456,
    "features": {
      "cluster_id": 0,
      "current_module_id": 65,
      "module_progress": 0.5,
      "avg_score": 0.6,
      "recent_action_type": 0
    },
    "top_k": 5
  }'

# 4. Get model info
curl http://localhost:8080/api/model-info
```

**Expected Response:**
```json
{
  "success": true,
  "student_id": 123,
  "cluster_id": 2,
  "cluster_name": "Medium",
  "state_vector": [2.0, 2.0, 0.75, 1.0, 1, 1],
  "state_description": {
    "cluster_id": 2,
    "cluster_name": "Medium",
    "module_index": 2,
    "progress_label": "75%",
    "score_label": "100%",
    "learning_phase": 1,
    "learning_phase_name": "active",
    "engagement_level": 1,
    "engagement_name": "medium",
    "state_format": "6D"
  },
  "recommendations": [
    {
      "action_id": 2,
      "action_type": "attempt_quiz",
      "time_context": "past",
      "module_name": "attempt_quiz (past)",
      "q_value": 42.182,
      "activity_id": 63,
      "activity_name": "bÃ i kiá»ƒm tra bÃ i 2 - medium",
      "target_los": [["LO1.5", 0.4]],
      "explanation": "Cáº£i thiá»‡n LO1.5 (hiá»‡n táº¡i 40.0%) â†’ dá»± kiáº¿n tÄƒng 5.0% (lÃªn 45.0%): ...",
      "alternatives": []
    }
  ],
  "model_info": {
    "model_version": "V2",
    "n_states_in_qtable": 7779
  }
}
```

### 5. Simulation

```bash
# Simulate learning path vá»›i trained model
python3 simulate_learning_path.py \
    --qtable models/qtable_best.pkl \
    --students 3 \
    --steps 30 \
    --verbose
```

---

## ğŸ“Š Cáº¥u trÃºc Dá»± Ã¡n

```
step7_qlearning/
â”œâ”€â”€ ğŸ“‚ core/                          # Core components
â”‚   â”œâ”€â”€ qlearning_agent_v2.py        # Q-Learning agent
â”‚   â”œâ”€â”€ state_builder_v2.py          # State builder (7D) vá»›i convert_7d_to_6d()
â”‚   â”œâ”€â”€ reward_calculator_v2.py      # Cluster-adaptive rewards + LO tracking
â”‚   â”œâ”€â”€ action_space.py              # Action definitions (15 actions)
â”‚   â”œâ”€â”€ activity_recommender.py      # Intelligent activity selection + LO prediction
â”‚   â”œâ”€â”€ lo_mastery_tracker.py       # LO mastery tracking & midterm prediction
â”‚   â”œâ”€â”€ learning_path_simulator.py   # Complete simulation system
â”‚   â”œâ”€â”€ state_transition_logger.py   # Detailed logging
â”‚   â”œâ”€â”€ qtable_adapter.py          # Convert module IDs â†” action indices
â”‚   â””â”€â”€ student.py                   # Student model
â”‚
â”œâ”€â”€ ğŸ“‚ services/                      # Services
â”‚   â”œâ”€â”€ model_loader.py              # Load models
â”‚   â”œâ”€â”€ cluster_service.py           # Cluster prediction
â”‚   â”œâ”€â”€ qtable_service.py            # Q-table inspection
â”‚   â””â”€â”€ recommendation_service.py   # Recommendation engine
â”‚
â”œâ”€â”€ ğŸ“‚ models/                        # Trained models
â”‚   â””â”€â”€ qtable_best.pkl             # V2 model (7,779+ states) â­
â”‚
â”œâ”€â”€ ğŸ“‚ data/                          # Data files
â”‚   â”œâ”€â”€ course_structure.json        # Moodle course structure
â”‚   â”œâ”€â”€ cluster_profiles.json        # Cluster profiles
â”‚   â”œâ”€â”€ Po_Lo.json                   # LO â†’ Activity mappings
â”‚   â”œâ”€â”€ midterm_lo_weights.json      # Midterm LO weights
â”‚   â””â”€â”€ log/, simulated/             # Logs and simulations
â”‚
â”œâ”€â”€ ğŸ“„ api_service.py                # FastAPI service â­
â”œâ”€â”€ ğŸ“„ train_qlearning.py            # Training script â­
â”œâ”€â”€ ğŸ“„ simulate_learning_path.py     # Simulation script â­
â””â”€â”€ ğŸ“„ requirements.txt               # Dependencies
```

---

## ğŸ“ˆ Performance Metrics

### Model Performance
- **Training episodes**: 1,000+
- **Average reward**: 195.66+
- **Q-table coverage**: 18.2%+
- **State space**: 7,779+ trained states
- **Actions**: 15 action types â†’ 37 learning activities

### API Performance
- **Response time**: < 50ms
- **Success rate**: > 95%
- **Concurrent requests**: Supports multiple students

---

## ğŸ¯ State Representation

### State Vector (6D)

**6D Format**:
```python
state = (cluster_id, module_idx, progress_bin, score_bin, 
         learning_phase, engagement_level)
```

| Dimension | Values | Description |
|-----------|--------|-------------|
| **cluster_id** | 0-4 | Student cluster (exclude teacher) |
| **module_idx** | 0-5 | Current module index |
| **progress_bin** | 0.25, 0.5, 0.75, 1.0 | Quartile binned progress |
| **score_bin** | 0.25, 0.5, 0.75, 1.0 | Quartile binned score |
| **learning_phase** | 0, 1, 2 | pre/active/reflective |
| **engagement_level** | 0, 1, 2 | low/medium/high |

**Note**: State Ä‘Æ°á»£c build tá»« `features` vá»›i **5 trÆ°á»ng input** táº¡o ra **6D state**:

**Input Features (5 trÆ°á»ng)**:
1. `cluster_id` (int): Cluster ID cá»§a há»c sinh (0-4, sau khi map vÃ  exclude teacher cluster) â†’ **dim 0**
2. `current_module_id` (int): Module ID tá»« course structure â†’ **dim 1** (map thÃ nh `module_idx` 0-5)
3. `module_progress` (float): Tiáº¿n Ä‘á»™ module (0-1) â†’ **dim 2** (bin thÃ nh `progress_bin`: 0.25, 0.5, 0.75, 1.0)
4. `avg_score` (float): Äiá»ƒm trung bÃ¬nh (0-1) â†’ **dim 3** (bin thÃ nh `score_bin`: 0.25, 0.5, 0.75, 1.0)
5. `recent_action_type` (int, optional, default=0): Loáº¡i hÃ nh Ä‘á»™ng gáº§n nháº¥t (0-5) â†’ **dim 4 + dim 5**:
   - **dim 4**: `learning_phase` (0=pre-learning, 1=active-learning, 2=reflective-learning)
   - **dim 5**: `engagement_level` (0=low, 1=medium, 2=high, dá»±a trÃªn action weights vÃ  consistency)

**ğŸ’¡ LÆ°u Ã½**: `recent_action_type` (1 trÆ°á»ng) Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ tÃ­nh **2 dimensions** (`learning_phase` vÃ  `engagement_level`), nÃªn 5 trÆ°á»ng input â†’ 6D state.

**Mapping `recent_action_type`**:
- 0 â†’ `view_content` (weight: 1)
- 1 â†’ `submit_quiz` (weight: 5)
- 2 â†’ `post_forum` (weight: 3)
- 3 â†’ `review_quiz` (weight: 3)
- 4 â†’ `read_resource` (weight: 1)
- 5 â†’ `submit_assignment` (weight: 5)

CÃ¡c trÆ°á»ng khÃ¡c trong `features` (nhÆ° `is_stuck`, `quiz_attempts`, `quiz_failures`, `time_on_module`) lÃ  optional vÃ  khÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng trong state building.

### Action Types (15)
```python
# Past actions (5)
- view_assignment (past)
- view_content (past)
- attempt_quiz (past)
- review_quiz (past)
- post_forum (past)

# Current actions (7)
- view_assignment (current)
- view_content (current)
- submit_assignment (current)
- attempt_quiz (current)
- submit_quiz (current)
- review_quiz (current)
- post_forum (current)

# Future actions (3)
- view_content (future)
- attempt_quiz (future)
- post_forum (future)
```

---

## ğŸ’¡ Use Cases

### 1. Real-time Recommendations vá»›i Activity Details
```python
from services.model_loader import ModelLoader
from services.recommendation_service import RecommendationService
from pathlib import Path

# Load model
loader = ModelLoader(
    model_path=Path('models/qtable_best.pkl'),
    course_path=Path('data/course_structure.json'),
    cluster_profiles_path=Path('data/cluster_profiles.json')
)
loader.load_all(verbose=False)

# Create service
service = RecommendationService(
    agent=loader.agent,
    action_space=loader.action_space,
    state_builder=loader.state_builder,
    course_structure_path=str(Path('data/course_structure.json'))
)

# Get recommendations vá»›i LO mastery
features = {
    'cluster_id': 2,
    'current_module_id': 67,
    'module_progress': 0.75,
    'avg_score': 0.85,
    'recent_action_type': 1
}

state = service.build_state_from_features(features, cluster_id=2)
lo_mastery = {'LO1.1': 0.4, 'LO2.2': 0.25, 'LO2.4': 0.4}

recommendations = service.get_recommendations(
    state=state,
    cluster_id=2,
    top_k=5,
    lo_mastery=lo_mastery,
    module_idx=int(state[1])
)

# Má»—i recommendation cÃ³:
for rec in recommendations:
    print(f"{rec['module_name']} (Q={rec['q_value']:.3f})")
    print(f"  Activity: {rec.get('activity_name')} (ID: {rec.get('activity_id')})")
    print(f"  Explanation: {rec.get('explanation')}")
    print(f"  Target LOs: {rec.get('target_los')}")
```

### 2. Training vá»›i Detailed Logging
```bash
python3 train_qlearning.py \
    --episodes 100 \
    --detailed-logging \
    --log-interval 10
```

### 3. Learning Path Simulation
```bash
python3 simulate_learning_path.py \
    --qtable models/qtable_best.pkl \
    --students 5 \
    --steps 50 \
    --verbose
```

---

## ğŸ”§ Configuration

### config/reward_config.json
```json
{
  "reward_components": {
    "completion": {"weak": 5.0, "medium": 3.5, "strong": 2.0},
    "score_improvement": {"multiplier": 5.0},
    "high_score_bonus": {"threshold": 0.9},
    "progression": {...},
    "lo_mastery_improvement": {...}
  }
}
```

### Q-Learning Hyperparameters
```python
LEARNING_RATE = 0.1      # Î±
DISCOUNT_FACTOR = 0.95   # Î³
EPSILON = 0.1            # Îµ (exploration)
EPSILON_DECAY = 0.995
EPSILON_MIN = 0.01
```

---

## ğŸ“š Documentation

- **README.md** (this file) - Tá»•ng quan vÃ  quick start
- **ARCHITECTURE.md** - Kiáº¿n trÃºc há»‡ thá»‘ng chi tiáº¿t
- **USAGE_GUIDE.md** - API, Training, Simulation guides

---

## ğŸ› Troubleshooting

### Issue: API returns q_values=0
**Solution**: Retrain model
```bash
python3 train_qlearning.py --episodes 1000
```

### Issue: Module not found errors
**Solution**: Check course_structure.json
```bash
python3 -c "import json; print(len(json.load(open('data/course_structure.json'))['modules']))"
```

### Issue: Cluster mapping errors
**Solution**: Verify cluster_profiles.json
```bash
python3 -c "import json; print(json.load(open('data/cluster_profiles.json'))['n_clusters'])"
```

---

## ğŸ‘¥ Contributors

Developed for Adaptive Learning Research Project

## ğŸ“„ License

Internal Research Project
