#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Cluster Profiler Module (LLM-powered)
======================================
S·ª≠ d·ª•ng LLM ƒë·ªÉ ph√¢n t√≠ch v√† m√¥ t·∫£ ƒë·∫∑c ƒëi·ªÉm c·ªßa t·ª´ng cluster
"""

import pandas as pd
import numpy as np
import json
from pathlib import Path
from typing import Dict, List, Optional
import logging

logger = logging.getLogger(__name__)


class ClusterProfiler:
    """
    Ph√¢n t√≠ch v√† m√¥ t·∫£ ƒë·∫∑c ƒëi·ªÉm c·ªßa t·ª´ng cluster s·ª≠ d·ª•ng LLM
    
    Features:
    - T√≠nh to√°n statistical profile cho m·ªói cluster
    - S·ª≠ d·ª•ng LLM (Gemini/OpenAI) ƒë·ªÉ generate m√¥ t·∫£ t·ª± nhi√™n
    - So s√°nh cluster v·ªõi overall population
    - T·∫°o actionable insights v√† recommendations
    """
    
    def __init__(self, llm_provider: str = 'gemini', api_key: Optional[str] = None):
        """
        Args:
            llm_provider: 'gemini' ho·∫∑c 'openai'
            api_key: API key (n·∫øu None, s·∫Ω ƒë·ªçc t·ª´ env variable)
        """
        self.llm_provider = llm_provider.lower()
        self.api_key = api_key
        self.llm_client = None
        self.cluster_profiles = {}
        
        self._initialize_llm()
    
    def _initialize_llm(self):
        """Initialize LLM client"""
        try:
            if self.llm_provider == 'gemini':
                import google.generativeai as genai
                import os
                
                api_key = self.api_key or os.getenv('GOOGLE_API_KEY') or os.getenv('GEMINI_API_KEY')
                
                # Try importing from config if available
                if not api_key:
                    try:
                        import sys
                        from pathlib import Path
                        parent_dir = Path(__file__).parent.parent
                        if str(parent_dir) not in sys.path:
                            sys.path.insert(0, str(parent_dir))
                        from config import GEMINI_API_KEY
                        api_key = GEMINI_API_KEY
                        logger.info("‚úì Loaded API key from config.py")
                    except (ImportError, AttributeError):
                        pass
                
                if not api_key:
                    raise ValueError("Gemini API key not found. Set GOOGLE_API_KEY or GEMINI_API_KEY environment variable.")
                
                genai.configure(api_key=api_key)
                # S·ª≠ d·ª•ng gemini-2.5-flash (model m·ªõi, thay th·∫ø gemini-1.5-flash)
                self.llm_client = genai.GenerativeModel('gemini-2.5-flash')
                logger.info("‚úì Initialized Gemini LLM (gemini-2.5-flash)")
                
            elif self.llm_provider == 'openai':
                from openai import OpenAI
                import os
                
                api_key = self.api_key or os.getenv('OPENAI_API_KEY')
                if not api_key:
                    raise ValueError("OpenAI API key not found. Set OPENAI_API_KEY environment variable.")
                
                self.llm_client = OpenAI(api_key=api_key)
                logger.info("‚úì Initialized OpenAI LLM")
                
            else:
                raise ValueError(f"Unsupported LLM provider: {self.llm_provider}. Use 'gemini' or 'openai'")
                
        except Exception as e:
            logger.error(f"Failed to initialize LLM: {e}")
            logger.warning("‚ö† LLM not available. Will generate basic profiles without AI descriptions.")
            self.llm_client = None
    
    def calculate_cluster_statistics(self, df: pd.DataFrame, cluster_col: str = 'cluster') -> Dict:
        """
        T√≠nh to√°n statistics cho t·ª´ng cluster
        
        Args:
            df: DataFrame ch·ª©a data v·ªõi cluster labels
            cluster_col: T√™n column ch·ª©a cluster ID
            
        Returns:
            Dict v·ªõi cluster statistics
        """
        logger.info("Calculating cluster statistics...")
        
        # Get feature columns (exclude metadata)
        exclude_cols = ['userid', 'cluster', 'group']
        feature_cols = [col for col in df.columns if col not in exclude_cols]
        
        # Overall statistics
        overall_stats = {
            'mean': df[feature_cols].mean().to_dict(),
            'std': df[feature_cols].std().to_dict(),
            'median': df[feature_cols].median().to_dict()
        }
        
        # Per-cluster statistics
        cluster_stats = {}
        
        for cluster_id in sorted(df[cluster_col].unique()):
            cluster_df = df[df[cluster_col] == cluster_id]
            n_students = len(cluster_df)
            pct_students = (n_students / len(df)) * 100
            
            # Feature statistics
            cluster_mean = cluster_df[feature_cols].mean()
            cluster_std = cluster_df[feature_cols].std()
            cluster_median = cluster_df[feature_cols].median()
            
            # Compare to overall (z-score like)
            deviation_from_overall = {}
            for feat in feature_cols:
                if overall_stats['std'][feat] > 0:
                    z_score = (cluster_mean[feat] - overall_stats['mean'][feat]) / overall_stats['std'][feat]
                    deviation_from_overall[feat] = float(z_score)
                else:
                    deviation_from_overall[feat] = 0.0
            
            # Identify top distinguishing features (highest absolute deviation)
            top_features = sorted(deviation_from_overall.items(), 
                                 key=lambda x: abs(x[1]), 
                                 reverse=True)[:5]
            
            cluster_stats[int(cluster_id)] = {
                'cluster_id': int(cluster_id),
                'n_students': int(n_students),
                'percentage': float(pct_students),
                'feature_means': {k: float(v) for k, v in cluster_mean.items()},
                'feature_stds': {k: float(v) for k, v in cluster_std.items()},
                'feature_medians': {k: float(v) for k, v in cluster_median.items()},
                'deviation_from_overall': deviation_from_overall,
                'top_distinguishing_features': [
                    {
                        'feature': feat,
                        'z_score': float(z_score),
                        'interpretation': 'much higher' if z_score > 1.5 else 
                                        'higher' if z_score > 0.5 else
                                        'much lower' if z_score < -1.5 else
                                        'lower' if z_score < -0.5 else
                                        'similar'
                    }
                    for feat, z_score in top_features
                ]
            }
        
        self.cluster_profiles = {
            'overall_stats': overall_stats,
            'cluster_stats': cluster_stats,
            'n_clusters': len(cluster_stats),
            'total_students': len(df),
            'features_analyzed': feature_cols
        }
        
        logger.info(f"‚úì Calculated statistics for {len(cluster_stats)} clusters")
        return self.cluster_profiles
    
    def generate_llm_description(self, cluster_id: int) -> str:
        """
        S·ª≠ d·ª•ng LLM ƒë·ªÉ generate m√¥ t·∫£ t·ª± nhi√™n cho cluster
        
        Args:
            cluster_id: ID c·ªßa cluster c·∫ßn m√¥ t·∫£
            
        Returns:
            M√¥ t·∫£ b·∫±ng ti·∫øng Vi·ªát
        """
        if not self.llm_client:
            return "LLM not available. Using basic description."
        
        cluster_data = self.cluster_profiles['cluster_stats'][cluster_id]
        
        # Prepare prompt
        prompt = f"""
B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch d·ªØ li·ªáu gi√°o d·ª•c. H√£y ph√¢n t√≠ch v√† m√¥ t·∫£ ƒë·∫∑c ƒëi·ªÉm c·ªßa nh√≥m h·ªçc sinh sau:

**Th√¥ng tin nh√≥m:**
- S·ªë l∆∞·ª£ng: {cluster_data['n_students']} h·ªçc sinh ({cluster_data['percentage']:.1f}% t·ªïng s·ªë)
- Top 5 ƒë·∫∑c ƒëi·ªÉm n·ªïi b·∫≠t:
{self._format_top_features(cluster_data['top_distinguishing_features'])}

**Y√™u c·∫ßu:**
1. ƒê·∫∑t t√™n cho nh√≥m n√†y (v√≠ d·ª•: "H·ªçc sinh xu·∫•t s·∫Øc", "H·ªçc sinh c·∫ßn h·ªó tr·ª£", v.v.)
2. M√¥ t·∫£ ƒë·∫∑c ƒëi·ªÉm h·ªçc t·∫≠p c·ªßa nh√≥m (2-3 c√¢u)
3. Ph√¢n t√≠ch ƒëi·ªÉm m·∫°nh v√† ƒëi·ªÉm y·∫øu
4. ƒê·ªÅ xu·∫•t 2-3 h√†nh ƒë·ªông c·ª• th·ªÉ ƒë·ªÉ h·ªó tr·ª£/ph√°t tri·ªÉn nh√≥m n√†y

**ƒê·ªãnh d·∫°ng tr·∫£ v·ªÅ (JSON):**
{{
    "name": "T√™n nh√≥m",
    "description": "M√¥ t·∫£ ng·∫Øn g·ªçn",
    "strengths": ["ƒêi·ªÉm m·∫°nh 1", "ƒêi·ªÉm m·∫°nh 2"],
    "weaknesses": ["ƒêi·ªÉm y·∫øu 1", "ƒêi·ªÉm y·∫øu 2"],
    "recommendations": ["H√†nh ƒë·ªông 1", "H√†nh ƒë·ªông 2", "H√†nh ƒë·ªông 3"]
}}

Ch·ªâ tr·∫£ v·ªÅ JSON, kh√¥ng th√™m text kh√°c.
"""
        
        try:
            if self.llm_provider == 'gemini':
                response = self.llm_client.generate_content(prompt)
                result_text = response.text
            else:  # openai
                response = self.llm_client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "You are an educational data analyst. Always respond in Vietnamese and return valid JSON."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.7
                )
                result_text = response.choices[0].message.content
            
            # Parse JSON from response
            result_text = result_text.strip()
            if result_text.startswith('```json'):
                result_text = result_text[7:]
            if result_text.startswith('```'):
                result_text = result_text[3:]
            if result_text.endswith('```'):
                result_text = result_text[:-3]
            result_text = result_text.strip()
            
            result = json.loads(result_text)
            return result
            
        except Exception as e:
            logger.error(f"LLM generation failed for cluster {cluster_id}: {e}")
            return self._generate_fallback_description(cluster_id)
    
    def _generate_all_clusters_description(self) -> Dict[int, Dict]:
        """
        Generate descriptions for ALL clusters in ONE LLM request
        Optimized to reduce API calls and avoid quota issues
        
        Returns:
            Dict mapping cluster_id to profile dict
        """
        if not self.llm_client:
            logger.warning("LLM not available, using fallback descriptions")
            return {cid: self._generate_fallback_description(cid) 
                    for cid in self.cluster_profiles['cluster_stats'].keys()}
        
        try:
            # Build comprehensive prompt for all clusters
            prompt_parts = [
                "B·∫°n l√† chuy√™n gia ph√¢n t√≠ch d·ªØ li·ªáu h·ªçc t·∫≠p. Ph√¢n t√≠ch c√°c nh√≥m h·ªçc sinh sau v√† t·∫°o m√¥ t·∫£ CHI TI·∫æT cho T·ª™NG NH√ìM.",
                f"\nT·ªïng s·ªë h·ªçc sinh: {self.cluster_profiles['total_students']}",
                f"S·ªë nh√≥m: {self.cluster_profiles['n_clusters']}\n"
            ]
            
            # Add info for each cluster
            for cluster_id, stats in sorted(self.cluster_profiles['cluster_stats'].items()):
                prompt_parts.append(f"\n--- NH√ìM {cluster_id} ---")
                prompt_parts.append(f"S·ªë l∆∞·ª£ng: {stats['n_students']} h·ªçc sinh ({stats['percentage']:.1f}%)")
                prompt_parts.append(f"\nƒê·∫∑c ƒëi·ªÉm n·ªïi b·∫≠t:")
                prompt_parts.append(self._format_top_features(stats['top_distinguishing_features']))
            
            prompt_parts.append("\n\nY√äU C·∫¶U OUTPUT (JSON):")
            prompt_parts.append("Tr·∫£ v·ªÅ JSON object v·ªõi key l√† cluster_id (s·ªë nguy√™n), value l√† object c√≥:")
            prompt_parts.append("- name: T√™n nh√≥m ng·∫Øn g·ªçn, s√∫c t√≠ch (VD: 'H·ªçc sinh t√≠ch c·ª±c')")
            prompt_parts.append("- description: M√¥ t·∫£ t·ªïng quan 2-3 c√¢u v·ªÅ ƒë·∫∑c ƒëi·ªÉm nh√≥m")
            prompt_parts.append("- characteristics: M·∫£ng 3-5 ƒëi·ªÉm ƒë·∫∑c tr∆∞ng ch√≠nh (m·ªói ƒëi·ªÉm 1 c√¢u)")
            prompt_parts.append("- recommendations: M·∫£ng 2-3 g·ª£i √Ω can thi·ªáp/h·ªó tr·ª£ (m·ªói g·ª£i √Ω 1 c√¢u)")
            prompt_parts.append("\nV√≠ d·ª• format:")
            prompt_parts.append('''{
  "0": {
    "name": "H·ªçc sinh ch·ªß ƒë·ªông",
    "description": "Nh√≥m n√†y th·ªÉ hi·ªán s·ª± t√≠ch c·ª±c cao trong h·ªçc t·∫≠p v·ªõi nhi·ªÅu ho·∫°t ƒë·ªông t∆∞∆°ng t√°c.",
    "characteristics": [
      "Tham gia th∆∞·ªùng xuy√™n v√†o c√°c b√†i t·∫≠p v√† th·∫£o lu·∫≠n",
      "C√≥ xu h∆∞·ªõng ho√†n th√†nh b√†i t·∫≠p tr∆∞·ªõc deadline",
      "T∆∞∆°ng t√°c nhi·ªÅu v·ªõi t√†i li·ªáu h·ªçc li·ªáu"
    ],
    "recommendations": [
      "T·∫°o th√™m b√†i t·∫≠p n√¢ng cao ƒë·ªÉ th·ª≠ th√°ch",
      "Khuy·∫øn kh√≠ch l√†m mentor cho c√°c b·∫°n kh√°c"
    ]
  }
}''')
            
            prompt = '\n'.join(prompt_parts)
            
            # Call LLM
            if self.llm_provider == 'gemini':
                response = self.llm_client.generate_content(prompt)
                result_text = response.text
            elif self.llm_provider == 'openai':
                response = self.llm_client.chat.completions.create(
                    model="gpt-4",
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.7
                )
                result_text = response.choices[0].message.content
            else:
                raise ValueError(f"Unsupported LLM provider: {self.llm_provider}")
            
            # Parse JSON
            result_text = result_text.strip()
            if result_text.startswith('```json'):
                result_text = result_text[7:]
            elif result_text.startswith('```'):
                result_text = result_text[3:]
            if result_text.endswith('```'):
                result_text = result_text[:-3]
            result_text = result_text.strip()
            
            all_profiles = json.loads(result_text)
            
            # Convert string keys to int
            return {int(k): v for k, v in all_profiles.items()}
            
        except Exception as e:
            logger.error(f"LLM batch generation failed: {e}")
            logger.warning("Falling back to individual fallback descriptions")
            return {cid: self._generate_fallback_description(cid) 
                    for cid in self.cluster_profiles['cluster_stats'].keys()}
    
    def _format_top_features(self, top_features: List[Dict]) -> str:
        """Format top features cho prompt"""
        lines = []
        for feat_data in top_features:
            feat = feat_data['feature']
            interp = feat_data['interpretation']
            z = feat_data['z_score']
            lines.append(f"  - {feat}: {interp} (z-score: {z:.2f})")
        return '\n'.join(lines)
    
    def _generate_fallback_description(self, cluster_id: int) -> Dict:
        """Generate basic description khi LLM kh√¥ng available"""
        cluster_data = self.cluster_profiles['cluster_stats'][cluster_id]
        
        # Simple rule-based naming
        pct = cluster_data['percentage']
        if pct > 40:
            name = "Nh√≥m ƒëa s·ªë"
        elif pct < 10:
            name = "Nh√≥m thi·ªÉu s·ªë"
        else:
            name = f"Nh√≥m {cluster_id + 1}"
        
        # Get top features for characteristics
        top_features = cluster_data.get('top_distinguishing_features', [])[:3]
        characteristics = [
            f"{feat['feature'].replace('_', ' ').title()}: {feat['interpretation']}"
            for feat in top_features
        ] if top_features else ["ƒê·∫∑c ƒëi·ªÉm c·∫ßn ph√¢n t√≠ch th√™m"]
        
        return {
            'name': name,
            'description': f"Nh√≥m g·ªìm {cluster_data['n_students']} h·ªçc sinh ({pct:.1f}%), c·∫ßn ph√¢n t√≠ch chi ti·∫øt ƒë·ªÉ hi·ªÉu r√µ ƒë·∫∑c ƒëi·ªÉm.",
            'characteristics': characteristics,
            'recommendations': [
                "Theo d√µi ho·∫°t ƒë·ªông h·ªçc t·∫≠p c·ªßa nh√≥m",
                "Ph√¢n t√≠ch th√™m ƒë·ªÉ ƒë∆∞a ra can thi·ªáp ph√π h·ª£p"
            ]
        }
    
    def profile_all_clusters(self, df: pd.DataFrame, cluster_col: str = 'cluster') -> Dict:
        """
        Ph√¢n t√≠ch v√† m√¥ t·∫£ t·∫•t c·∫£ c√°c cluster c√πng l√∫c (t·ªëi ∆∞u API calls)
        
        Args:
            df: DataFrame ch·ª©a data v·ªõi cluster labels
            cluster_col: T√™n column ch·ª©a cluster ID
            
        Returns:
            Dict v·ªõi cluster profiles
        """
        logger.info("="*70)
        logger.info("CLUSTER PROFILING WITH LLM")
        logger.info("="*70)
        
        # Calculate statistics (already done if called externally)
        if not self.cluster_profiles or 'cluster_stats' not in self.cluster_profiles:
            self.calculate_cluster_statistics(df, cluster_col)
        
        # Generate LLM descriptions for ALL clusters at once
        logger.info("\nü§ñ Generating AI-powered descriptions for all clusters in one request...")
        
        llm_profiles = self._generate_all_clusters_description()
        
        # Create structured profiles
        profiles_dict = {}
        for cluster_id, stats in self.cluster_profiles['cluster_stats'].items():
            profile = llm_profiles.get(cluster_id, {
                'name': f'Cluster {cluster_id}',
                'description': f"Nh√≥m g·ªìm {stats['n_students']} h·ªçc sinh ({stats['percentage']:.1f}%).",
                'characteristics': [],
                'recommendations': []
            })
            
            profiles_dict[cluster_id] = {
                'cluster_id': cluster_id,
                'name': profile.get('name', f'Cluster {cluster_id}'),
                'description': profile.get('description', ''),
                'characteristics': profile.get('characteristics', []),
                'recommendations': profile.get('recommendations', []),
                'llm_description': profile  # Keep full LLM response for compatibility
            }
            
            logger.info(f"  ‚úì Cluster {cluster_id}: {profile.get('name', 'N/A')}")
        
        logger.info("\n" + "="*70)
        logger.info(f"‚úì Profiled {len(profiles_dict)} clusters")
        logger.info("="*70)
        
        return {
            'cluster_stats': self.cluster_profiles['cluster_stats'],
            'profiles': profiles_dict,
            'n_clusters': len(profiles_dict)
        }
    
    def save_profiles(self, output_dir: str):
        """
        L∆∞u cluster profiles
        
        Args:
            output_dir: Directory to save profiles
        """
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # Save JSON
        json_path = output_path / 'cluster_profiles.json'
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(self.cluster_profiles, f, indent=2, ensure_ascii=False)
        logger.info(f"  ‚úì Saved: {json_path}")
        
        # Save human-readable report
        self._save_text_report(output_path)
    
    def _save_text_report(self, output_path: Path):
        """L∆∞u b√°o c√°o text d·ªÖ ƒë·ªçc"""
        text_lines = []
        text_lines.append("="*80)
        text_lines.append("CLUSTER PROFILING REPORT (AI-POWERED)")
        text_lines.append("="*80)
        text_lines.append(f"\nT·ªïng s·ªë h·ªçc sinh: {self.cluster_profiles['total_students']}")
        text_lines.append(f"S·ªë c·ª•m: {self.cluster_profiles['n_clusters']}")
        text_lines.append(f"S·ªë features ph√¢n t√≠ch: {len(self.cluster_profiles['features_analyzed'])}")
        
        for cluster_id in sorted(self.cluster_profiles['cluster_stats'].keys()):
            data = self.cluster_profiles['cluster_stats'][cluster_id]
            ai_profile = data.get('ai_profile', {})
            
            text_lines.append("\n" + "="*80)
            text_lines.append(f"CLUSTER {cluster_id}: {ai_profile.get('name', 'N/A')}")
            text_lines.append("="*80)
            text_lines.append(f"\nüìä Th·ªëng k√™:")
            text_lines.append(f"  ‚Ä¢ S·ªë l∆∞·ª£ng: {data['n_students']} h·ªçc sinh ({data['percentage']:.1f}%)")
            
            text_lines.append(f"\nüìù M√¥ t·∫£:")
            text_lines.append(f"  {ai_profile.get('description', 'N/A')}")
            
            text_lines.append(f"\nüí™ ƒêi·ªÉm m·∫°nh:")
            for strength in ai_profile.get('strengths', []):
                text_lines.append(f"  ‚Ä¢ {strength}")
            
            text_lines.append(f"\n‚ö†Ô∏è ƒêi·ªÉm y·∫øu:")
            for weakness in ai_profile.get('weaknesses', []):
                text_lines.append(f"  ‚Ä¢ {weakness}")
            
            text_lines.append(f"\nüí° ƒê·ªÅ xu·∫•t h√†nh ƒë·ªông:")
            for i, rec in enumerate(ai_profile.get('recommendations', []), 1):
                text_lines.append(f"  {i}. {rec}")
            
            text_lines.append(f"\nüîç Top 5 ƒë·∫∑c ƒëi·ªÉm n·ªïi b·∫≠t:")
            for feat_data in data['top_distinguishing_features']:
                feat = feat_data['feature']
                interp = feat_data['interpretation']
                z = feat_data['z_score']
                text_lines.append(f"  ‚Ä¢ {feat}: {interp} (z-score: {z:.2f})")
        
        text_lines.append("\n" + "="*80)
        text_lines.append("END OF REPORT")
        text_lines.append("="*80)
        
        text_path = output_path / 'cluster_profiles_report.txt'
        with open(text_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(text_lines))
        logger.info(f"  ‚úì Saved: {text_path}")


if __name__ == '__main__':
    # Test
    logging.basicConfig(level=logging.INFO,
                       format='%(asctime)s - %(levelname)s - %(message)s')
    
    # Create sample data
    np.random.seed(42)
    data = {
        'userid': range(1, 101),
        'feature1': np.random.rand(100),
        'feature2': np.random.rand(100),
        'feature3': np.random.rand(100),
        'cluster': np.random.choice([0, 1, 2], 100)
    }
    df = pd.DataFrame(data)
    
    # Profile clusters
    profiler = ClusterProfiler(llm_provider='gemini')
    profiles = profiler.profile_all_clusters(df)
    profiler.save_profiles('test_output')
