# Moodle Analytics Pipeline - GMM-Based

## üéØ Overview

**Moodle Analytics Pipeline** l√† h·ªá th·ªëng ph√¢n t√≠ch v√† sinh d·ªØ li·ªáu h·ªçc sinh **d·ª±a tr√™n Gaussian Mixture Model (GMM)** - thay th·∫ø ho√†n to√†n ph∆∞∆°ng ph√°p rule-based simulation tr∆∞·ªõc ƒë√¢y.

### ‚ú® ƒêi·ªÉm m·ªõi so v·ªõi phi√™n b·∫£n c≈©

- ‚úÖ **Feature Selection t·ª± ƒë·ªông**: Lo·∫°i b·ªè features kh√¥ng c·∫ßn thi·∫øt d·ª±a tr√™n variance v√† correlation
- ‚úÖ **Optimal Clustering v·ªõi GMM**: T·ª± ƒë·ªông t√¨m s·ªë c·ª•m t·ªëi ∆∞u (BIC, AIC, Silhouette)
- ‚úÖ **GMM-based Data Generation**: Sinh d·ªØ li·ªáu synthetic t·ª´ GMM (kh√¥ng c√≤n rule-based)
- ‚úÖ **Comprehensive Validation**: Statistical tests (KS test, Chi-square) v√† comparison
- ‚úÖ **T·ª± ƒë·ªông h√≥a ho√†n to√†n**: Kh√¥ng c·∫ßn can thi·ªáp th·ªß c√¥ng
- ‚úÖ **Khoa h·ªçc v√† minh b·∫°ch**: M·ªçi quy·∫øt ƒë·ªãnh ƒë·ªÅu c√≥ metrics v√† visualizations

---

## üîÑ Pipeline Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   MOODLE ANALYTICS PIPELINE                      ‚îÇ
‚îÇ                        (GMM-BASED)                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üìä PHASE 1: Feature Extraction
   ‚îú‚îÄ Load grades & logs data
   ‚îú‚îÄ Extract features (events, actions, grades, etc.)
   ‚îî‚îÄ Normalize features (MinMax/Z-score)
   
üîç PHASE 2: Feature Selection
   ‚îú‚îÄ Calculate variance scores
   ‚îú‚îÄ Filter low-variance features
   ‚îú‚îÄ Detect high-correlation features
   ‚îú‚îÄ Rank and select optimal features
   ‚îî‚îÄ Output: Selected features list
   
üéØ PHASE 3: Optimal Clustering (GMM)
   ‚îú‚îÄ Test k from 2 to 10
   ‚îú‚îÄ Calculate BIC, AIC, Silhouette for each k
   ‚îú‚îÄ Select optimal k (composite score)
   ‚îú‚îÄ Fit GMM with optimal k
   ‚îî‚îÄ Output: Optimal k, GMM model, clusters
   
üîÆ PHASE 4: GMM Data Generation
   ‚îú‚îÄ Load real data with selected features
   ‚îú‚îÄ Sample synthetic data from GMM
   ‚îú‚îÄ Assign cluster labels and quality groups
   ‚îú‚îÄ Visualize real vs synthetic (PCA, distributions)
   ‚îî‚îÄ Output: Synthetic students dataset
   
‚úÖ PHASE 5: Validation
   ‚îú‚îÄ Statistical tests (KS test for each feature)
   ‚îú‚îÄ Distribution comparison (mean, std, skewness)
   ‚îú‚îÄ Correlation matrix similarity
   ‚îú‚îÄ Cluster distribution comparison (Chi-square)
   ‚îú‚îÄ Calculate overall quality score
   ‚îî‚îÄ Output: Validation report + visualizations
   
üìà PHASE 6: Additional Comparison
   ‚îî‚îÄ Generate additional comparison plots
```

---

## üöÄ Quick Start

### Installation

```bash
# Clone repository
cd demo_pineline/moodle_analytics_pipeline

# Install dependencies
pip install -r requirements.txt
```

### Run Pipeline

```bash
python main.py
```

Ho·∫∑c t√πy ch·ªânh parameters:

```python
from core import MoodleAnalyticsPipeline

pipeline = MoodleAnalyticsPipeline(base_output_dir='outputs')

results = pipeline.run_full_pipeline(
    grades_path='../data/udk_moodle_grades_course_670.filtered.csv',
    logs_path='../data/udk_moodle_log_course_670.filtered.csv',
    n_synthetic_students=200,         # S·ªë h·ªçc sinh synthetic
    variance_threshold=0.01,          # Threshold l·ªçc variance
    correlation_threshold=0.95,       # Threshold l·ªçc correlation
    max_features=15,                  # Max s·ªë features ch·ªçn
    k_range=range(2, 11)             # Range k ƒë·ªÉ test
)
```

---

## üìä Output Structure

```
outputs/
‚îú‚îÄ‚îÄ features/                          # PHASE 1
‚îÇ   ‚îú‚îÄ‚îÄ features_raw.csv
‚îÇ   ‚îú‚îÄ‚îÄ features_scaled.json
‚îÇ   ‚îî‚îÄ‚îÄ feature_statistics.json
‚îÇ
‚îú‚îÄ‚îÄ feature_selection/                 # PHASE 2
‚îÇ   ‚îú‚îÄ‚îÄ feature_selection_analysis.png
‚îÇ   ‚îú‚îÄ‚îÄ feature_selection_report.json
‚îÇ   ‚îî‚îÄ‚îÄ feature_selection_report.txt
‚îÇ
‚îú‚îÄ‚îÄ optimal_clusters/                  # PHASE 3
‚îÇ   ‚îú‚îÄ‚îÄ optimal_clusters_evaluation.png
‚îÇ   ‚îú‚îÄ‚îÄ optimal_clusters_report.json
‚îÇ   ‚îî‚îÄ‚îÄ optimal_clusters_report.txt
‚îÇ
‚îú‚îÄ‚îÄ gmm_generation/                    # PHASE 4
‚îÇ   ‚îú‚îÄ‚îÄ synthetic_students_gmm.csv
‚îÇ   ‚îú‚îÄ‚îÄ synthetic_students_gmm.json
‚îÇ   ‚îú‚îÄ‚îÄ gmm_generation_summary.json
‚îÇ   ‚îú‚îÄ‚îÄ real_vs_synthetic_pca.png
‚îÇ   ‚îú‚îÄ‚îÄ feature_distributions_comparison.png
‚îÇ   ‚îî‚îÄ‚îÄ correlation_comparison.png
‚îÇ
‚îú‚îÄ‚îÄ validation/                        # PHASE 5
‚îÇ   ‚îú‚îÄ‚îÄ validation_report.json
‚îÇ   ‚îú‚îÄ‚îÄ validation_report.txt
‚îÇ   ‚îú‚îÄ‚îÄ ks_test_results.png
‚îÇ   ‚îî‚îÄ‚îÄ distribution_boxplots.png
‚îÇ
‚îî‚îÄ‚îÄ comparison/                        # PHASE 6
    ‚îî‚îÄ‚îÄ (additional comparison plots)
```

---

## üß™ Core Modules

### 1. FeatureExtractor
Tr√≠ch xu·∫•t features t·ª´ Moodle logs v√† grades.

### 2. FeatureSelector ‚≠ê NEW
- T√≠nh variance v√† correlation scores
- Lo·∫°i b·ªè low-variance features
- Lo·∫°i b·ªè highly-correlated features (redundant)
- Rank features theo importance

### 3. OptimalClusterFinder ‚≠ê NEW
- Test multiple k values (2-10)
- Calculate BIC, AIC, Silhouette
- Automated optimal k selection
- Comprehensive evaluation plots

### 4. GMMDataGenerator ‚≠ê NEW
- Fit GMM on real data
- Sample synthetic data from GMM distribution
- Assign cluster labels v√† quality groups
- Validate distribution similarity

### 5. ValidationMetrics ‚≠ê NEW
- Kolmogorov-Smirnov tests
- Distribution comparisons
- Correlation matrix similarity
- Overall quality scoring

---

## üìà Key Metrics

### Feature Selection Metrics
- **Variance score**: ƒê·ªô bi·∫øn thi√™n c·ªßa feature
- **Correlation score**: ƒê·ªô t∆∞∆°ng quan gi·ªØa features
- **Composite score**: T·ªïng h·ª£p variance + stability

### Clustering Metrics
- **BIC (Bayesian Information Criterion)**: Lower is better
- **AIC (Akaike Information Criterion)**: Lower is better
- **Silhouette Score**: 0-1, higher is better (>0.5: good)
- **Composite Score**: Weighted combination (0-1)

### Validation Metrics
- **KS Test p-value**: >0.05 ‚Üí distributions are similar
- **Chi-square p-value**: >0.05 ‚Üí cluster distributions are similar
- **Correlation Similarity**: 0-1, higher is better
- **Overall Quality Score**: 0-100% (Excellent: >85%, Good: >70%)

---

## üéì Scientific Approach

### 1. Feature Selection
- **Variance threshold**: Lo·∫°i b·ªè features c√≥ variance < 0.01 (√≠t th√¥ng tin)
- **Correlation threshold**: Lo·∫°i b·ªè features c√≥ correlation > 0.95 (redundant)
- **Ranking**: Composite score = 0.7 √ó variance + 0.3 √ó stability

### 2. Optimal Clustering
- **Strategy**: Test k t·ª´ 2-10, t√≠nh BIC/AIC/Silhouette cho m·ªói k
- **Selection**: Ch·ªçn k c√≥ composite score cao nh·∫•t (0.5√óBIC + 0.5√óSilhouette)
- **Validation**: Ki·ªÉm tra convergence v√† iteration count

### 3. GMM Data Generation
- **Model**: Gaussian Mixture Model v·ªõi covariance_type='full'
- **Sampling**: Sample t·ª´ GMM distribution (kh√¥ng d√πng mean+noise nh∆∞ c≈©)
- **Labeling**: T·ª± ƒë·ªông map clusters sang quality labels (gi·ªèi/kh√°/y·∫øu)

### 4. Validation
- **Statistical tests**: KS test (m·ªói feature), Chi-square test (cluster distribution)
- **Quality score**: 0.4√óKS_pass_rate + 0.3√ócorr_similarity + 0.3√ó(1-mean_error)

---

## üîß Configuration

Edit `config.py` ƒë·ªÉ t√πy ch·ªânh:

```python
# Feature Selection
VARIANCE_THRESHOLD = 0.01
CORRELATION_THRESHOLD = 0.95
MAX_SELECTED_FEATURES = 15

# GMM Clustering
MIN_CLUSTERS = 2
MAX_CLUSTERS = 10
GMM_COVARIANCE_TYPE = 'full'

# Generation
N_SYNTHETIC_STUDENTS = 200

# Validation
KS_TEST_ALPHA = 0.05
MIN_QUALITY_SCORE_EXCELLENT = 85
MIN_QUALITY_SCORE_GOOD = 70
```

---

## üìù Example Usage

### Basic Usage
```python
from core import MoodleAnalyticsPipeline

pipeline = MoodleAnalyticsPipeline()
results = pipeline.run_full_pipeline(
    grades_path='data/grades.csv',
    logs_path='data/logs.csv'
)

print(f"Optimal k: {results['optimal_k']}")
print(f"Quality Score: {results['validation_results']['overall_quality_score']['score']:.1f}%")
```

### Advanced Usage - Custom Modules
```python
from core import (
    FeatureExtractor,
    FeatureSelector,
    OptimalClusterFinder,
    GMMDataGenerator,
    ValidationMetrics
)

# 1. Extract features
extractor = FeatureExtractor()
features = extractor.process_pipeline(grades_path, logs_path, output_dir)

# 2. Select features
selector = FeatureSelector(variance_threshold=0.01, correlation_threshold=0.95)
selected = selector.process_pipeline(features, output_dir)

# 3. Find optimal k
finder = OptimalClusterFinder(k_range=range(2, 11))
optimal_k, gmm = finder.process_pipeline(features[selected].values, output_dir)

# 4. Generate synthetic data
generator = GMMDataGenerator(optimal_gmm=gmm)
synthetic = generator.process_pipeline(
    features_path, selected, optimal_k, n_synthetic=200, output_dir
)

# 5. Validate
validator = ValidationMetrics()
results = validator.process_pipeline(real_path, synthetic_path, selected, output_dir)

print(f"Quality: {results['overall_quality_score']['grade']}")
```

---

## üìö References

- **GMM**: Gaussian Mixture Models for clustering
- **BIC/AIC**: Model selection criteria
- **Silhouette Score**: Cluster quality metric
- **KS Test**: Distribution similarity test

---

## ü§ù Contributing

Pull requests are welcome! For major changes, please open an issue first.

---

## üìÑ License

MIT License

---

## üîó Related Files

- `QUICKSTART.md`: Quick start guide with examples
- `MODULE_SUMMARY.md`: Detailed module documentation
- `METRICS_GUIDE.md`: Metrics explanation
- `config.py`: Configuration parameters

---

**Last Updated**: November 2025  
**Version**: 3.0 (GMM-based)
