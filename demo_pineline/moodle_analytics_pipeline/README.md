# Moodle Analytics Pipeline (KMeans-Only)

## Overview

Streamlined pipeline that extracts features from Moodle logs/grades, selects optimal features, finds optimal clusters with KMeans (voting across Elbow, Silhouette, Davies-Bouldin), profiles clusters with AI, and visualizes results. GMM synthetic generation and validation phases have been removed for simplicity.

### ‚ú® ƒêi·ªÉm m·ªõi so v·ªõi phi√™n b·∫£n c≈©

- ‚úÖ **Feature Selection t·ª± ƒë·ªông**: Lo·∫°i b·ªè features kh√¥ng c·∫ßn thi·∫øt d·ª±a tr√™n variance v√† correlation
- ‚úÖ **Optimal Clustering v·ªõi GMM**: T·ª± ƒë·ªông t√¨m s·ªë c·ª•m t·ªëi ∆∞u (BIC, AIC, Silhouette)
- ‚úÖ **GMM-based Data Generation**: Sinh d·ªØ li·ªáu synthetic t·ª´ GMM (kh√¥ng c√≤n rule-based)
- ‚úÖ **Comprehensive Validation**: Statistical tests (KS test, Chi-square) v√† comparison
- ‚úÖ **T·ª± ƒë·ªông h√≥a ho√†n to√†n**: Kh√¥ng c·∫ßn can thi·ªáp th·ªß c√¥ng
- ‚úÖ **Khoa h·ªçc v√† minh b·∫°ch**: M·ªçi quy·∫øt ƒë·ªãnh ƒë·ªÅu c√≥ metrics v√† visualizations

---

## Pipeline Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   MOODLE ANALYTICS PIPELINE                      ‚îÇ
‚îÇ                        (GMM-BASED)                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üìä PHASE 1: Feature Extraction
   ‚îú‚îÄ Load grades & logs data
   ‚îú‚îÄ Extract features (events, actions, grades, etc.)
   ‚îî‚îÄ Normalize features (MinMax/Z-score)
   
üîç PHASE 2: Feature Selection
   ‚îú‚îÄ Calculate variance scores
   ‚îú‚îÄ Filter low-variance features
   ‚îú‚îÄ Detect high-correlation features
   ‚îú‚îÄ Rank and select optimal features
   ‚îî‚îÄ Output: Selected features list
   
üéØ PHASE 3: Optimal Clustering (KMeans + Voting)
   ‚îú‚îÄ Test k from 2 to 10
   ‚îú‚îÄ Calculate Elbow, Silhouette, Davies-Bouldin for each k
   ‚îú‚îÄ Select optimal k (composite voting)
   ‚îî‚îÄ Output: Optimal k, KMeans model, clusters
   
ü§ñ PHASE 4: Cluster Profiling with AI
   ‚îú‚îÄ Assign cluster labels to real data
   ‚îú‚îÄ Generate AI narratives per cluster
   ‚îî‚îÄ Output: Cluster profiles (JSON + TXT)
   
üìà PHASE 5: Visualization
   ‚îú‚îÄ Feature distributions
   ‚îú‚îÄ Cluster separation plots
   ‚îî‚îÄ Output: Comparison plots
   
üìà PHASE 6: Additional Comparison
   ‚îî‚îÄ Generate additional comparison plots
```

---

## Quick Start

### Installation

```bash
# Clone repository
cd demo_pineline/moodle_analytics_pipeline

# Install dependencies
pip install -r requirements.txt
```

### Run Pipeline

```bash
python3 main.py
```

Ho·∫∑c t√πy ch·ªânh parameters:

```python
from core import MoodleAnalyticsPipeline

pipeline = MoodleAnalyticsPipeline(base_output_dir='outputs')

results = pipeline.run_full_pipeline(
    grades_path='../data/udk_moodle_grades_course_670.filtered.csv',
    logs_path='../data/udk_moodle_log_course_670.filtered.csv',
   variance_threshold=0.01,          # Threshold l·ªçc variance
   correlation_threshold=0.95,       # Threshold l·ªçc correlation
   max_features=15,                  # Max s·ªë features ch·ªçn
   k_range=range(2, 11)              # Range k ƒë·ªÉ test
)
```

---

## üìä Output Structure

```
outputs/
‚îú‚îÄ‚îÄ features/                          # PHASE 1
‚îÇ   ‚îú‚îÄ‚îÄ features_raw.csv
‚îÇ   ‚îú‚îÄ‚îÄ features_scaled.json
‚îÇ   ‚îî‚îÄ‚îÄ feature_statistics.json
‚îÇ
‚îú‚îÄ‚îÄ feature_selection/                 # PHASE 2
‚îÇ   ‚îú‚îÄ‚îÄ feature_selection_analysis.png
‚îÇ   ‚îú‚îÄ‚îÄ feature_selection_report.json
‚îÇ   ‚îî‚îÄ‚îÄ feature_selection_report.txt
‚îÇ
‚îú‚îÄ‚îÄ optimal_clusters/                  # PHASE 3
‚îÇ   ‚îú‚îÄ‚îÄ optimal_clusters_evaluation.png
‚îÇ   ‚îú‚îÄ‚îÄ optimal_clusters_report.json
‚îÇ   ‚îî‚îÄ‚îÄ optimal_clusters_report.txt
‚îÇ
‚îú‚îÄ‚îÄ comparison/                        # PHASE 5
‚îÇ   ‚îú‚îÄ‚îÄ feature_distributions.png
‚îÇ   ‚îú‚îÄ‚îÄ cluster_scatter.png
‚îÇ   ‚îî‚îÄ‚îÄ comparison_summary.txt
‚îÇ
‚îî‚îÄ‚îÄ comparison/                        # PHASE 6
    ‚îî‚îÄ‚îÄ (additional comparison plots)
```

---

## üß™ Core Modules

### 1. FeatureExtractor
Tr√≠ch xu·∫•t features t·ª´ Moodle logs v√† grades.

### 2. FeatureSelector ‚≠ê NEW
- T√≠nh variance v√† correlation scores
- Lo·∫°i b·ªè low-variance features
- Lo·∫°i b·ªè highly-correlated features (redundant)
- Rank features theo importance

### 3. OptimalClusterFinder ‚≠ê NEW
- Test multiple k values (2-10)
- Calculate BIC, AIC, Silhouette
- Automated optimal k selection
- Comprehensive evaluation plots

### 4. ClusterProfiler
- Generate AI-powered descriptions and recommendations per cluster

### 5. ComparisonVisualizer
- Feature distributions and basic cluster visualizations

---

## üìà Key Metrics

### Feature Selection Metrics
- **Variance score**: ƒê·ªô bi·∫øn thi√™n c·ªßa feature
- **Correlation score**: ƒê·ªô t∆∞∆°ng quan gi·ªØa features
- **Composite score**: T·ªïng h·ª£p variance + stability

### Clustering Metrics
- **BIC (Bayesian Information Criterion)**: Lower is better
- **AIC (Akaike Information Criterion)**: Lower is better
- **Silhouette Score**: 0-1, higher is better (>0.5: good)
- **Composite Score**: Weighted combination (0-1)

### Validation Metrics
- **KS Test p-value**: >0.05 ‚Üí distributions are similar
- **Chi-square p-value**: >0.05 ‚Üí cluster distributions are similar
- **Correlation Similarity**: 0-1, higher is better
- **Overall Quality Score**: 0-100% (Excellent: >85%, Good: >70%)

---

## üéì Scientific Approach

### 1. Feature Selection
- **Variance threshold**: Lo·∫°i b·ªè features c√≥ variance < 0.01 (√≠t th√¥ng tin)
- **Correlation threshold**: Lo·∫°i b·ªè features c√≥ correlation > 0.95 (redundant)
- **Ranking**: Composite score = 0.7 √ó variance + 0.3 √ó stability

### 2. Optimal Clustering
- **Strategy**: Test k t·ª´ 2-10, t√≠nh BIC/AIC/Silhouette cho m·ªói k
- **Selection**: Ch·ªçn k c√≥ composite score cao nh·∫•t (0.5√óBIC + 0.5√óSilhouette)
- **Validation**: Ki·ªÉm tra convergence v√† iteration count

### 3. Cluster Profiling
- AI narratives per cluster for interpretability

### 4. Visualization
- Basic plots for distributions and cluster separation

---

## üîß Configuration

Edit `config.py` ƒë·ªÉ t√πy ch·ªânh:

```python
# Feature Selection
VARIANCE_THRESHOLD = 0.01
CORRELATION_THRESHOLD = 0.95
MAX_SELECTED_FEATURES = 15

# GMM Clustering
MIN_CLUSTERS = 2
MAX_CLUSTERS = 10
GMM_COVARIANCE_TYPE = 'full'

# Generation
N_SYNTHETIC_STUDENTS = 200

# Validation
KS_TEST_ALPHA = 0.05
MIN_QUALITY_SCORE_EXCELLENT = 85
MIN_QUALITY_SCORE_GOOD = 70
```

---

## üìù Example Usage

### Basic Usage
```python
from core import MoodleAnalyticsPipeline

pipeline = MoodleAnalyticsPipeline()
results = pipeline.run_full_pipeline(
    grades_path='data/grades.csv',
    logs_path='data/logs.csv'
)

print(f"Optimal k: {results['optimal_k']}")
print(f"Quality Score: {results['validation_results']['overall_quality_score']['score']:.1f}%")
```

### Advanced Usage - Custom Modules
```python
from core import (
   FeatureExtractor,
   FeatureSelector,
   OptimalClusterFinder,
   ClusterProfiler,
   ComparisonVisualizer
)

# 1. Extract features
extractor = FeatureExtractor()
features = extractor.process_pipeline(grades_path, logs_path, output_dir)

# 2. Select features
selector = FeatureSelector(variance_threshold=0.01, correlation_threshold=0.95)
selected = selector.process_pipeline(features, output_dir)

# 3. Find optimal k
finder = OptimalClusterFinder(k_range=range(2, 11))
optimal_k, gmm = finder.process_pipeline(features[selected].values, output_dir)

# 4. Profile clusters with AI
profiler = ClusterProfiler()
profiler.profile_all_clusters(df=features, cluster_col='cluster')
profiler.save_profiles('outputs/cluster_profiling')
```

---

## üìö References

- **GMM**: Gaussian Mixture Models for clustering
- **BIC/AIC**: Model selection criteria
- **Silhouette Score**: Cluster quality metric
- **KS Test**: Distribution similarity test

---

## ü§ù Contributing

Pull requests are welcome! For major changes, please open an issue first.

---

## üìÑ License

MIT License

---

## üîó Related Files

- `QUICKSTART.md`: Quick start guide with examples
- `MODULE_SUMMARY.md`: Detailed module documentation
- `METRICS_GUIDE.md`: Metrics explanation
- `config.py`: Configuration parameters

---

**Last Updated**: December 2025  
**Version**: 4.0 (KMeans-only)
